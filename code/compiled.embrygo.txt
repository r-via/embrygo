# === Directory Tree for Local Path: 'code' ===
# (Source: /home/rviau/flashsight/embrygo/code)
# (Options: no gitignore used, user dir excludes: [statics, www], user file excludes: [_templ.go, htmx.min.js, package-lock.json])
# (Permanently Excluded: .git, config.compiled.*.yaml)
# (File content read with UTF-8 encoding, 'replace' error handling for decode issues)
# (Dirs/Files marked [Content Omitted] exist but their content is excluded based on rules/extensions)
# ======================================================================
# code
# ├── cmd/
# │   └── service-app/
# │       └── main.go
# ├── internal/
# │   ├── config/
# │   │   └── config.go
# │   ├── database/
# │   │   ├── .gitkeep [Content Omitted]
# │   │   └── database.go
# │   ├── handlers/
# │   │   ├── api/
# │   │   │   ├── .gitkeep [Content Omitted]
# │   │   │   └── handler.go
# │   │   └── web/
# │   │       └── handler.go
# │   ├── middleware/
# │   │   ├── .gitkeep [Content Omitted]
# │   │   └── middleware.go
# │   ├── models/
# │   │   ├── .gitkeep [Content Omitted]
# │   │   └── common.go
# │   ├── router/
# │   │   ├── .gitkeep [Content Omitted]
# │   │   └── router.go
# │   └── services/
# │       ├── welcome/
# │       │   ├── .gitkeep [Content Omitted]
# │       │   ├── model.go
# │       │   ├── repository.go
# │       │   └── service.go
# │       └── .gitkeep [Content Omitted]
# ├── pkg/
# │   ├── helpers/
# │   │   └── helpers.go
# │   └── translations/
# │       └── translations.go
# ├── tools/
# │   ├── input.css
# │   ├── package-lock.json [Content Omitted]
# │   ├── package.json [Content Omitted]
# │   ├── requirements.txt [Content Omitted]
# │   └── tailwind.config.js
# ├── webroot/
# │   ├── sources/
# │   │   ├── .gitkeep [Content Omitted]
# │   │   └── app.js
# │   ├── views/
# │   │   ├── layouts/
# │   │   │   └── base.templ
# │   │   └── pages/
# │   │       └── welcome.templ
# │   └── statics/ [Content Omitted: Dirs: 0, Files: 2]
# ├── .air.toml [Content Omitted]
# ├── .env.example [Content Omitted]
# ├── Makefile [Content Omitted]
# ├── README.md
# ├── compiled.embrygo.txt [Content Omitted]
# ├── go.mod [Content Omitted]
# └── go.sum [Content Omitted]
# ======================================================================

# === Go Package Trees ===
# (Permanently Excluded: .git)
# ======================================================================

# --- Tree for Package: github.com/r-via/blitzkit ---
# ----------------------------------------------------------------------
# package:github.com/r-via/blitzkit
# ├── assets/
# │   └── imgs/
# │       └── logo.jpg [Content Omitted]
# ├── .gitignore [Content Omitted]
# ├── LICENSE [Content Omitted]
# ├── README.md [Content Omitted]
# ├── cache.go
# ├── cache_methods.go
# ├── error_handling.go
# ├── go.mod [Content Omitted]
# ├── go.sum [Content Omitted]
# ├── middleware.go
# ├── monitoring.go
# ├── server.go
# ├── sitemap.go
# ├── static_processor.go
# ├── types.go
# └── utils.go
# ----------------------------------------------------------------------

# ======================================================================

# === Compiled File Contents ===
# ======================================================================

# --- Content from Path: 'code' (Source: /home/rviau/flashsight/embrygo/code, Extensions: [.css, .go, .js, .md, .templ, Makefile]) ---

# File: README.md
# ------------------------------------------------------------
# EmbryGo: github.com/r-via/embrygo

Minimalist Go & Templ Web Starter with HTMX & Tailwind CSS.

Based on the BlitzKit stack, EmbryGo provides a clean foundation to kickstart your Go web projects.
It features a Go backend (powered by Fiber & BlitzKit), server-side Templ components,
HTMX for dynamic UI, and Tailwind CSS with DaisyUI for styling.
Includes live-reload, build tools, and best practices.

## Features

*   **Go Backend**: Fiber framework with a BlitzKit server layer (logging, config, CSRF, security, static file processing).
*   **Templ**: Type-safe HTML templating directly in Go.
*   **HTMX**: For enhancing HTML with AJAX capabilities without complex JavaScript.
*   **Tailwind CSS & DaisyUI**: Utility-first CSS for rapid UI development.
*   **Heroicons**: SVG icons as Templ components, generated by `templ-heroicons-generator`.
*   **Live Reload**: Using Air for development.
*   **Makefile**: For easy build, run, and utility commands.
*   **Configuration**: `.env` file support.
*   **Logging**: Structured logging with `slog`.

## Project Structure

(You can add a brief overview of the generated structure here later)

## Prerequisites (Development)

*   Go (e.g., 1.21+)
*   Node.js and npm (for Tailwind CSS & DaisyUI)
*   Python 3.8+ (with `venv` module)
*   Templ CLI (`go install github.com/a-h/templ/cmd/templ@latest`)
*   Air (`go install github.com/cosmtrek/air@latest`)

The `templ-heroicons-generator` Python package will be installed in a local virtual environment via the Makefile.

## Getting Started

1.  **Clone or Generate:**
    This project is typically generated by a script. If you cloned it, proceed.

2.  **Copy Environment Configuration:**
    ```bash
    cp .env.example .env
    ```
    Modify `.env` as needed (especially `APP_BASE_URL` if not `http://localhost:8080`).

3.  **Install Tools & Dependencies:**
    This command will set up Node.js dependencies (for Tailwind) and Python dependencies (for Heroicons generation) in local `tools/` subdirectories.
    ```bash
    make setup-tools
    ```

4.  **Run in Development Mode (with Live Reload):**
    This will build initial frontend assets and then start the Air live reloader.
    ```bash
    make run
    ```
    The application will be available at `http://localhost:PORT` (default: `http://localhost:8080`).
    The main page is `/welcome`.

5.  **Build for Production:**
    ```bash
    make build
    ```
    This creates an optimized binary in `./bin/service-app`.

6.  **Run Production Build:**
    ```bash
    make start-prod
    # or directly:
    # APP_ENV=production ./bin/service-app
    ```

## Available Makefile Targets

*   `make all` or `make build`: Builds the entire application.
*   `make run`: Runs the app in development mode with live reload.
*   `make clean`: Removes build artifacts and generated files.
*   `make setup-tools`: Installs Node.js and Python tool dependencies.
*   `make tailwind`: Generates Tailwind CSS.
*   `make heroicons`: Generates Heroicon Templ components.
*   `make templ-generate`: Compiles all `.templ` files to Go.
*   `make copy-statics`: Copies files from `webroot/statics` to `webroot/www`.
*   `make minify-sources`: 'Minifies' (currently copies) `webroot/sources/app.js` to `webroot/www/js/app.js`.
*   `make start-prod`: Runs the production-built binary.
*   `make fmt`: Formats Go code.
*   `make tidy`: Tidies Go module dependencies.

## Technologies Used

*   Go
*   Fiber
*   BlitzKit (Custom Server Layer)
*   Templ
*   HTMX
*   Tailwind CSS
*   DaisyUI
*   Heroicons (via templ-heroicons-generator)
*   Slog
*   Air (Live Reload)

# File: cmd/service-app/main.go
# ------------------------------------------------------------
// File: cmd/service-app/main.go
package main

import (
	"errors"
	"fmt"
	"log/slog"
	"net/http"
	"net/url"
	"os"
	"os/signal"
	"strings"
	"syscall"
	"time"

	// EmbryGo internal packages
	"github.com/r-via/embrygo/internal/config"
	webHandlerPkg "github.com/r-via/embrygo/internal/handlers/web"

	// Third-party packages
	"github.com/gofiber/fiber/v2"
	"github.com/gofiber/fiber/v2/middleware/basicauth"
	"github.com/gofiber/fiber/v2/middleware/csrf"
	"github.com/gofiber/fiber/v2/middleware/requestid"
	"github.com/joho/godotenv"

	// BlitzKit (assumed to be an accessible module, e.g., github.com/r-via/blitzkit)
	"github.com/r-via/blitzkit"
)

func main() {
	// Attempt to load .env file. If it doesn't exist, continue gracefully.
	_ = godotenv.Load(".env")

	// Determine environment and logging settings
	isProduction := os.Getenv("APP_ENV") != "development"
	logLevel := slog.LevelInfo
	addSourceLog := false // Add source file/line to logs only in dev
	environmentName := "production"

	if !isProduction {
		logLevel = slog.LevelDebug
		addSourceLog = true
		environmentName = "development"
	}

	// Initialize structured logger (slog)
	handlerOpts := &slog.HandlerOptions{Level: logLevel, AddSource: addSourceLog}
	logger := slog.New(slog.NewTextHandler(os.Stdout, handlerOpts))
	slog.SetDefault(logger) // Make this logger the default for the application

	logger.Info("EmbryGo Application Starting...",
		"environment", environmentName,
		"module_path", "github.com/r-via/embrygo", // Replace with your actual module path from go.mod
	)

	// Load application-specific configuration from internal/config
	if err := config.LoadConfig(logger); err != nil {
		logger.Error("FATAL: Application config loading failed", "error", err)
		os.Exit(1)
	}

	// Determine the base path for the application from APP_BASE_URL
	// This is crucial for routing and asset URLs if deploying to a sub-path.
	basePath := "/"
	if config.AppConfig.AppBaseURL != "" {
		parsedURL, err := url.Parse(config.AppConfig.AppBaseURL)
		if err != nil {
			logger.Error("FATAL: Invalid APP_BASE_URL in .env or environment",
				"url", config.AppConfig.AppBaseURL, "error", err)
			os.Exit(1)
		}
		// Use the path component of the URL, ensuring it starts with '/' and doesn't end with one (unless it's just "/")
		if parsedURL.Path != "" && parsedURL.Path != "/" {
			basePath = strings.TrimSuffix(parsedURL.Path, "/")
			if !strings.HasPrefix(basePath, "/") {
				basePath = "/" + basePath
			}
		}
	}
	logger.Info("Using application base path for routing and assets",
		"derived_basePath", basePath,
		"source_APP_BASE_URL", config.AppConfig.AppBaseURL,
	)

	// Check for admin credentials (used for an example route)
	if config.AppConfig.AdminUser == "" || config.AppConfig.AdminPass == "" {
		logger.Warn("ADMIN_USER and/or ADMIN_PASS not set in .env. Example admin route will be unprotected or use defaults.")
	}

	// Define security headers (CSP is differentiated for dev/prod)
	defaultSecurityHeaders := map[string]string{
		"X-Frame-Options":           "SAMEORIGIN",
		"X-Content-Type-Options":    "nosniff",
		"Referrer-Policy":           "strict-origin-when-cross-origin",
		"Permissions-Policy":        "geolocation=(), microphone=(), camera=(), payment=(), interest-cohort=()",
		"X-XSS-Protection":          "1; mode=block",
		"Strict-Transport-Security": "max-age=31536000; includeSubDomains", // For HTTPS sites
	}
	// Looser CSP for development (allows WebSocket for live reload, inline styles/scripts if necessary)
	cspDev := "default-src 'self' ws:; script-src 'self' 'unsafe-inline'; style-src 'self' 'unsafe-inline'; img-src 'self' data:; font-src 'self' data:; object-src 'none'; frame-ancestors 'self';"
	// Stricter CSP for production
	cspProd := "default-src 'self'; script-src 'self'; style-src 'self' 'unsafe-inline'; img-src 'self' data:; font-src 'self' data:; object-src 'none'; frame-ancestors 'self';" // Allow 'unsafe-inline' for Tailwind/DaisyUI if no better solution for now

	if isProduction {
		defaultSecurityHeaders["Content-Security-Policy"] = cspProd
	} else {
		defaultSecurityHeaders["Content-Security-Policy"] = cspDev
	}

	// Configure BlitzKit server
	// Paths are relative to the project root where the binary is run.
	serverConfig := blitzkit.Config{
		Port:               os.Getenv("PORT"), // BlitzKit will default to 8080 if empty or invalid
		DevMode:            !isProduction,
		Logger:             logger,
		PublicDir:          "webroot/www",     // Processed static files are served from here
		CacheDir:           "webroot/cache",   // For L2 cache (BadgerDB)
		SourcesDir:         "webroot/sources", // JS/CSS to be minified by BlitzKit's StaticProcessor
		StaticsDir:         "webroot/statics", // Files to be copied as-is by BlitzKit's StaticProcessor
		EnableCSRF:         true,
		CSRFKeyLookup:      "header:X-CSRF-Token",                                  // HTMX sends token in this header
		CSRFCookieName:     "__Host-embrygo_csrf_",                                 // Secure prefix for production (HTTPS)
		CSRFExpiration:     12 * time.Hour,                                         // CSRF token validity
		CSRFCookieSameSite: "Lax",                                                  // Recommended SameSite policy
		SecurityHeaders:    defaultSecurityHeaders,                                 // Apply our defined security headers
		EnableMetrics:      true,                                                   // Expose Prometheus metrics at /metrics
		EnableRateLimiter:  false,                                                  // Keep false for simple EmbryGo starter
		// ErrorComponentGenerator: func(err error, code int, isDev bool) templ.Component { ... } // Optional: For custom error pages via Templ
	}
	if !isProduction {
		// For local development (often HTTP), __Host- prefix won't work.
		serverConfig.CSRFCookieName = "embrygo_csrf_dev_"
	}
	logger.Info("BlitzKit Server Effective Configuration Initializing...", slog.Any("config_summary",
		map[string]interface{}{
			"Port": serverConfig.Port, "DevMode": serverConfig.DevMode, "PublicDir": serverConfig.PublicDir,
			"CacheDir": serverConfig.CacheDir, "EnableCSRF": serverConfig.EnableCSRF, "EnableMetrics": serverConfig.EnableMetrics,
			"CSRFCookieName": serverConfig.CSRFCookieName,
		}))

	// Create the BlitzKit server instance
	// BlitzKit handles initialization of Fiber, its own base middlewares, static processing, and monitoring.
	server, errServer := blitzkit.NewServer(serverConfig)
	if errServer != nil {
		logger.Error("FATAL: Failed to initialize BlitzKit server", "error", errServer)
		os.Exit(1)
	}
	app := server.App() // Get the underlying Fiber app instance from BlitzKit

	// Initialize EmbryGo-specific web handlers
	webHandler := webHandlerPkg.NewHandler(server, logger)
	logger.Info("EmbryGo web handlers initialized.")

	// --- Application-Specific Middlewares (added after BlitzKit's base middlewares) ---
	app.Use(requestid.New()) // Add a unique Request ID to each request

	// Middleware to set the calculated `basePath` into Fiber's context locals.
	// This makes it available to handlers (e.g., for `assetUrl` in templates).
	app.Use(func(c *fiber.Ctx) error {
		c.Locals("basePath", basePath) // basePath is derived from APP_BASE_URL
		return c.Next()
	})
	logger.Info("Middleware for 'basePath' in locals has been set.")

	// Explicit CSRF Protection Middleware configuration (supplements/overrides BlitzKit's if it also sets one)
	// This gives EmbryGo direct control over CSRF settings.
	if serverConfig.EnableCSRF {
		csrfMw := csrf.New(csrf.Config{
			KeyLookup:      serverConfig.CSRFKeyLookup,
			CookieName:     serverConfig.CSRFCookieName,
			CookieSameSite: serverConfig.CSRFCookieSameSite,
			Expiration:     serverConfig.CSRFExpiration,
			CookieSecure:   isProduction, // CSRF cookie should be secure in production (HTTPS)
			CookieHTTPOnly: true,         // CSRF cookie should be HTTPOnly
			ContextKey:     blitzkit.CSRFContextKey, // Key to store token in c.Locals
			ErrorHandler: func(c *fiber.Ctx, err error) error {
				reqIDVal := c.Locals("requestid")
				reqID, _ := reqIDVal.(string)
				clientIP := blitzkit.GetClientIP(c.Get(fiber.HeaderXForwardedFor), c.IP())
				logger.Warn("CSRF validation failed",
					"ip", clientIP, "path", c.Path(), "request_id", reqID, "error_message", err.Error())
				// For HTMX, it's often better to return 403 and let HTMX handle it,
				// or a specific HTMX response if configured.
				// Defaulting to a standard 403 error page for now.
				return fiber.NewError(fiber.StatusForbidden, "CSRF token mismatch or missing. Please refresh the page and try again.")
			},
		})
		app.Use(csrfMw) // Apply CSRF protection globally or to specific groups
		logger.Info("CSRF protection middleware enabled explicitly by EmbryGo.")
	} else {
		// If CSRF is disabled, set a local so `getCsrfToken` in handlers can know.
		app.Use(func(c *fiber.Ctx) error {
			c.Locals(blitzkit.CSRFContextKey, "csrf-disabled")
			return c.Next()
		})
		logger.Warn("CSRF protection middleware IS DISABLED based on BlitzKit config.")
	}

	// --- Routing Setup ---
	// All application-specific routes will be grouped under the calculated `basePath`.
	// If basePath is "/", this is effectively `app.Group("/")`.
	// If basePath is "/myapp", routes will be `/myapp/welcome`, etc.
	rootGroup := app.Group(basePath)
	logger.Info("Registering EmbryGo application routes", "under_group_path_prefix", basePath)

	// Example Admin Route (optional, demonstrates BasicAuth with credentials from .env)
	if config.AppConfig.AdminUser != "" && config.AppConfig.AdminPass != "" {
		adminAuthConfig := basicauth.Config{
			Users: map[string]string{config.AppConfig.AdminUser: config.AppConfig.AdminPass},
			Realm: "EmbryGo Admin Area (Example)",
		}
		// This group will be at `basePath/admin-example`
		adminExampleGroup := rootGroup.Group("/admin-example", basicauth.New(adminAuthConfig))
		adminExampleGroup.Get("/", func(c *fiber.Ctx) error {
			return c.Status(fiber.StatusOK).SendString("Welcome to the (example) protected admin area of EmbryGo!")
		})
		logger.Info("Example admin route registered and protected", "full_path_example", basePath+"/admin-example")
	} else {
		// Unprotected version if credentials are not set
		rootGroup.Get("/admin-example", func(c *fiber.Ctx) error {
			return c.Status(fiber.StatusOK).SendString("Example admin area (Currently UNPROTECTED - Set ADMIN_USER/ADMIN_PASS in .env to protect).")
		})
		logger.Warn("Admin credentials not set; example admin route is UNPROTECTED.", "full_path_example", basePath+"/admin-example")
	}

	// Register web UI routes (e.g., /welcome) under the `rootGroup`
	webHandler.RegisterRoutes(rootGroup)
	logger.Info("EmbryGo Web UI routes (e.g., /welcome) registered successfully.")

	// Static File Serving for `webroot/www`
	// BlitzKit's `StaticProcessor` (run during `NewServer`) populates `webroot/www`.
	// This `app.Static` serves those files.
	// The first argument to `app.Static` is the URL prefix.
	// Since `webroot/www` contains `tailwind.css`, `app.js` at its root,
	// and `basePath` is our app's root, we serve from `basePath`.
	if _, errStat := os.Stat(serverConfig.PublicDir); errStat == nil {
		logger.Info("Registering static file serving for public assets.",
			"url_prefix", basePath, // Files in PublicDir will be available under this prefix
			"physical_directory", serverConfig.PublicDir)

		// Example: if basePath = "/myapp", then a file `webroot/www/style.css`
		// will be accessible at `http://host/myapp/style.css`.
		// If basePath = "/", then `webroot/www/style.css` is at `http://host/style.css`.
		app.Static(basePath, serverConfig.PublicDir, fiber.Static{
			Compress:      true,
			ByteRange:     true,
			Browse:        !isProduction, // Allow directory browsing in development for easier debugging
			CacheDuration: 1 * time.Hour, // Browser cache duration for static assets
			MaxAge:        3600,          // Corresponds to CacheDuration in seconds
		})
	} else {
		logger.Error("Public static directory not found, web UI assets (CSS, JS) may not be served!",
			"expected_path", serverConfig.PublicDir, "stat_error", errStat.Error())
	}
	// Note: BlitzKit's `setupMonitoring` registers /metrics and /health at the *true* root of the Fiber app (ignoring basePath).

	// --- Start Server ---
	// Run the server in a goroutine so it doesn't block the main thread (for graceful shutdown).
	go func() {
		if startErr := server.Start(); startErr != nil { // server.Start() is from BlitzKit
			// http.ErrServerClosed is expected on graceful shutdown, so don't treat it as a fatal crash.
			if !errors.Is(startErr, http.ErrServerClosed) {
				logger.Error("FATAL: Server failed to start or crashed unexpectedly.", "error", startErr)
				// Attempt to signal the current process to terminate for graceful shutdown handling.
				p, findErr := os.FindProcess(os.Getpid())
				if findErr == nil {
					// Send SIGTERM, which is caught by our signal handler below.
					if sigErr := p.Signal(syscall.SIGTERM); sigErr != nil {
						logger.Error("Failed to send SIGTERM to self after server crash", "error", sigErr)
						os.Exit(1) // Fallback to abrupt exit
					}
				} else {
					logger.Error("Failed to find own process after server crash", "error", findErr)
					os.Exit(1) // Fallback to abrupt exit
				}
			}
		}
	}()

	// --- Graceful Shutdown Handling ---
	// Wait for interrupt signals (Ctrl+C) or termination signals.
	quit := make(chan os.Signal, 1)
	signal.Notify(quit, syscall.SIGINT, syscall.SIGTERM)

	receivedSignal := <-quit // Block until a signal is received
	logger.Warn("Shutdown signal received.", "signal", receivedSignal.String())

	logger.Info("Initiating graceful shutdown sequence...")
	if shutdownErr := server.Shutdown(); shutdownErr != nil { // server.Shutdown() is from BlitzKit
		logger.Error("Error during server shutdown procedures", "error", shutdownErr)
	} else {
		logger.Info("Server shutdown sequence completed successfully.")
	}

	logger.Info("EmbryGo application has shut down.")
}

# File: internal/config/config.go
# ------------------------------------------------------------
package config

import (
	"fmt"
	"log/slog"
	"os"
	"strings"
)

type Config struct {
	AdminUser  string
	AdminPass  string
	AppBaseURL string
	DevMode    bool
}

var AppConfig Config

func LoadConfig(logger *slog.Logger) error {
	logger.Info("Loading EmbryGo application configuration...")

	AppConfig = Config{
		AdminUser:  os.Getenv("ADMIN_USER"),
		AdminPass:  os.Getenv("ADMIN_PASS"),
		AppBaseURL: os.Getenv("APP_BASE_URL"),
		DevMode:    os.Getenv("APP_ENV") == "development",
	}

	// Example: Make APP_BASE_URL required in production
	var missing []string
	if AppConfig.AppBaseURL == "" && AppConfig.DevMode == false {
		missing = append(missing, "APP_BASE_URL (required for production)")
	}
	// Add other critical checks if needed

	if len(missing) > 0 {
		errMsg := fmt.Sprintf("Missing required environment variables: %s", strings.Join(missing, ", "))
		logger.Error(errMsg)
		return fmt.Errorf(errMsg)
	}

	if AppConfig.AppBaseURL == "" && AppConfig.DevMode == true {
		defaultBaseURL := "http://localhost:" + os.Getenv("PORT")
        if os.Getenv("PORT") == "" { defaultBaseURL = "http://localhost:8080" }
		logger.Warn("APP_BASE_URL not set in .env, defaulting for development.", "default_base_url", defaultBaseURL)
        AppConfig.AppBaseURL = defaultBaseURL
	}


	logger.Info("EmbryGo application configuration loaded successfully.")
	return nil
}

# File: internal/database/database.go
# ------------------------------------------------------------
package database

import (
	"log/slog"
)

// InitDB - Placeholder for database initialization.
// For EmbryGo, this might not be needed initially.
func InitDB(logger *slog.Logger) error {
	logger.Info("Database initialization skipped for EmbryGo (placeholder).")
	return nil
}

// CloseDB - Placeholder for closing database connection.
func CloseDB(logger *slog.Logger) error {
	logger.Info("Database closing skipped for EmbryGo (placeholder).")
	return nil
}

# File: internal/handlers/api/handler.go
# ------------------------------------------------------------
package api

import (
	"log/slog"
	"github.com/gofiber/fiber/v2"
	"github.com/r-via/blitzkit"
)

type Handler struct {
	logger *slog.Logger
	server *blitzkit.Server
	// Add services if this API handler needs them
}

func NewAPIHandler(server *blitzkit.Server, logger *slog.Logger) *Handler {
	return &Handler{logger: logger, server: server}
}

// RegisterAPIRoutes - Placeholder for API routes. EmbryGo might not have any initially.
func (h *Handler) RegisterAPIRoutes(apiGroup fiber.Router) {
	h.logger.Info("API routes registration skipped for EmbryGo (placeholder).")
	// Example:
	// apiGroup.Get("/status", func(c *fiber.Ctx) error {
	//    return c.JSON(fiber.Map{"status": "API is active - placeholder"})
	// })
}

# File: internal/handlers/web/handler.go
# ------------------------------------------------------------
package web

import (
	"log/slog"
	"strings"
	"github.com/r-via/embrygo/pkg/translations"
	"github.com/r-via/embrygo/webroot/views/layouts"
	"github.com/r-via/embrygo/webroot/views/pages"

	"github.com/a-h/templ"
	"github.com/gofiber/fiber/v2"
	"github.com/gofiber/fiber/v2/middleware/adaptor"
	"github.com/r-via/blitzkit"
)

type Handler struct {
	logger *slog.Logger
	server *blitzkit.Server
	// No complex service needed for EmbryGo's welcome page
}

func NewHandler(server *blitzkit.Server, logger *slog.Logger) *Handler {
	if logger == nil || server == nil {
		slog.Error("FATAL: Web Handler for EmbryGo requires non-nil server and logger")
		panic("Web Handler initialization failed: missing critical dependencies")
	}
	return &Handler{logger: logger, server: server}
}

// RegisterRoutes registers the web routes for EmbryGo.
// It expects the rootGroup to be already prefixed with any basePath.
func (h *Handler) RegisterRoutes(rootGroup fiber.Router) {
	h.logger.Info("Registering EmbryGo web routes...")
	
	// The actual path will be basePath + "/welcome"
	rootGroup.Get("/welcome", h.handleWelcomePage)

	// Redirect from the basePath itself to /basePath/welcome
	rootGroup.Get("/", func(c *fiber.Ctx) error {
		// basePath is already handled by the group, so target is just "welcome"
		// However, c.Redirect needs the full path from the server root.
        // We get basePath from locals, which IS the full path from server root.
        currentBasePath, _ := c.Locals("basePath").(string)
        if currentBasePath == "/" { currentBasePath = "" } // Avoid //welcome

		targetRedirectPath := currentBasePath + "/welcome"
        
		h.logger.Debug("Redirecting from root of group to welcome", "from", c.Path(), "to", targetRedirectPath)
		return c.Redirect(targetRedirectPath, fiber.StatusFound)
	})
}

// getBasePathFromLocals retrieves the application's base path from Fiber's context locals.
// This base path is set by a middleware in main.go.
func getBasePathFromLocals(c *fiber.Ctx, logger *slog.Logger) string {
	basePathVal := c.Locals("basePath")
	basePath, ok := basePathVal.(string)
	if !ok {
		basePath = "/" // Default to root if not found or wrong type
		if logger != nil {
			logger.Warn("Could not get 'basePath' from locals or wrong type, defaulting to '/'", "type_found", basePathVal)
		}
	}
	return basePath
}

// getCsrfToken retrieves the CSRF token from Fiber's context locals.
// It checks if CSRF is enabled on the server.
func getCsrfToken(c *fiber.Ctx, server *blitzkit.Server) string {
	if server == nil || !server.GetConfig().EnableCSRF {
		return "" // CSRF not enabled or server not available
	}
	csrfVal := c.Locals(blitzkit.CSRFContextKey) // Use BlitzKit's constant
	if tokenStr, ok := csrfVal.(string); ok && tokenStr != "csrf-disabled" {
		return tokenStr
	}
	return "" // Token not found, or CSRF explicitly disabled for the request
}

func (h *Handler) handleWelcomePage(c *fiber.Ctx) error {
	lang := "en" // Simplified for EmbryGo starter
	trans := translations.GetTranslations(lang) // From pkg/translations
	
	// basePath is the full path from the server root, e.g., "/" or "/myapp"
	basePath := getBasePathFromLocals(c, h.logger)
	csrfToken := getCsrfToken(c, h.server)

	h.logger.Debug("Handling /welcome page", "lang", lang, "basePath", basePath, "csrf_present", csrfToken != "")

	pageData := pages.WelcomePageData{
		Lang:         lang,
		Translations: trans,
		Base: layouts.BaseData{
			Lang:         lang,
			PageTitle:    trans["welcome_title"],
			Translations: trans,
			CSRFToken:    csrfToken,
			BasePath:     basePath,
		},
		Utilities: []pages.UtilityStatus{
			{Name: "Go Backend", Status: "OK", Icon: "check_circle"},
			{Name: "Fiber Framework", Status: "OK", Icon: "check_circle"},
			{Name: "BlitzKit Server Layer", Status: "OK", Icon: "check_circle"},
			{Name: "Templ Templating", Status: "OK", Icon: "check_circle"},
			{Name: "HTMX", Status: "OK", Icon: "check_circle"},
			{Name: "Tailwind CSS", Status: "OK", Icon: "check_circle"},
			{Name: "DaisyUI", Status: "OK", Icon: "check_circle"},
			{Name: "Heroicons (templ-heroicons-generator)", Status: "OK", Icon: "check_circle"},
			{Name: "Slog Logging", Status: "OK", Icon: "check_circle"},
			{Name: "Air Live Reload (Dev)", Status: "OK", Icon: "check_circle"},
		},
	}

	// Use Fiber's adaptor to render the Templ component
	return adaptor.HTTPHandler(templ.Handler(pages.WelcomePage(pageData)))(c)
}

# File: internal/middleware/middleware.go
# ------------------------------------------------------------
package middleware

// This package is a placeholder for custom application-specific middlewares.
// For EmbryGo, most common middlewares (CSRF, RequestID, CORS, Recover, Logging, BasicAuth, Limiter)
// are expected to be provided or configured via BlitzKit or Fiber itself in main.go.

# File: internal/models/common.go
# ------------------------------------------------------------
package models

import "time"

// ExampleModel - Placeholder for common data models.
// For EmbryGo's simple welcome page, this might not be used.
// If you were to use a database (e.g., GORM), your models would go here.
type ExampleModel struct {
	ID        uint      `gorm:"primarykey"`
	CreatedAt time.Time
	Name      string
}

# File: internal/router/router.go
# ------------------------------------------------------------
package router

import (
    "log/slog"
	"github.com/gofiber/fiber/v2"
	// "{GO_MODULE_NAME}/internal/handlers/web" // Example if you had more handlers
)

// SetupRoutes configures the application's routes.
// For EmbryGo, routing is simple and handled in main.go by registering web.Handler.
// This is a placeholder for more complex routing scenarios.
func SetupRoutes(app *fiber.App, logger *slog.Logger /*, webHandler *web.Handler, apiHandler *api.Handler */) {
	logger.Info("Router setup skipped for EmbryGo (placeholder - routing handled in main.go).")
	// Example for a larger app:
	// api := app.Group("/api")
	// apiHandler.RegisterAPIRoutes(api)
	// webHandler.RegisterRoutes(app) // Or a specific web group
}

# File: internal/services/welcome/model.go
# ------------------------------------------------------------
package welcome

// WelcomeDataModel - Placeholder for service-specific models.
type WelcomeDataModel struct {
	Message string
}

# File: internal/services/welcome/repository.go
# ------------------------------------------------------------
package welcome

import "log/slog"

// Repository - Placeholder for data access logic for the welcome service.
type Repository struct {
	logger *slog.Logger
	// db *gorm.DB // Example
}

func NewWelcomeRepository(logger *slog.Logger /*, db *gorm.DB*/) *Repository {
	return &Repository{logger: logger /*, db: db*/}
}

// FetchData - Placeholder.
func (r *Repository) FetchData() (string, error) {
	r.logger.Info("WelcomeRepository.FetchData called (placeholder).")
	return "Data from WelcomeRepository (placeholder)", nil
}

# File: internal/services/welcome/service.go
# ------------------------------------------------------------
package welcome

import (
	"log/slog"
	// "github.com/r-via/embrygo/internal/services/welcome/model" // If you define specific models
	// "github.com/r-via/embrygo/internal/services/welcome/repository" // If you had a DB
)

type Service struct {
	logger *slog.Logger
	// repo   *repository.Repository // Example
}

func NewWelcomeService(logger *slog.Logger /*, repo *repository.Repository*/) *Service {
	return &Service{logger: logger /*, repo: repo*/}
}

// GetWelcomeData - Placeholder for fetching data for the welcome page.
// For EmbryGo, the data is static and defined in the web handler.
func (s *Service) GetWelcomeData() (string, error) {
	s.logger.Info("WelcomeService.GetWelcomeData called (placeholder).")
	return "Data from WelcomeService (placeholder)", nil
}

# File: pkg/helpers/helpers.go
# ------------------------------------------------------------
package helpers

import (
	"regexp"
	"strings"
)

var emailRegex = regexp.MustCompile(`^[a-z0-9._%+\-]+@[a-z0-9.\-]+\.[a-z]{2,}$`)

// IsValidEmail checks if the email string is a valid format.
func IsValidEmail(email string) bool {
	if email == "" {
		return false
	}
	return emailRegex.MatchString(strings.ToLower(email))
}

// Add other general-purpose helper functions here.

# File: pkg/translations/translations.go
# ------------------------------------------------------------
package translations

import "log/slog"

// TranslationsMap holds translations for different languages.
var TranslationsMap = map[string]map[string]string{
	"en": {
		"welcome_title":             "Welcome to EmbryGo!",
		"welcome_message":           "This is a minimal web application built with the EmbryGo stack.",
		"utilities_title":           "Core Technologies & Features Status:",
		"go_backend":                "Go Backend",
		"fiber_framework":           "Fiber Web Framework",
		"blitzkit_server":           "BlitzKit Server Layer",
		"templ_templating":          "Templ (Type-Safe HTML)",
		"htmx":                      "HTMX (Dynamic HTML)",
		"tailwind_css":              "Tailwind CSS",
		"daisy_ui":                  "DaisyUI (Tailwind Components)",
		"heroicons_generator":       "Heroicons (via templ-heroicons-generator)",
		"slog_logging":              "Slog (Structured Logging)",
		"air_live_reload":           "Air (Live Reload - Dev)",
        "status_ok":                 "OK",
        "footer_text":               "EmbryGo Starter Project",
        "current_year":              "2024", // This could be dynamic
	},
	"fr": { // Example for another language
		"welcome_title":             "Bienvenue sur EmbryGo !",
		"welcome_message":           "Ceci est une application web minimale construite avec la stack EmbryGo.",
		"utilities_title":           "Statut des Technologies & Fonctionnalités Clés :",
		"go_backend":                "Backend Go",
		"fiber_framework":           "Framework Web Fiber",
		"blitzkit_server":           "Couche Serveur BlitzKit",
		"templ_templating":          "Templ (HTML Typé)",
		"htmx":                      "HTMX (HTML Dynamique)",
		"tailwind_css":              "Tailwind CSS",
		"daisy_ui":                  "DaisyUI (Composants Tailwind)",
		"heroicons_generator":       "Heroicons (via templ-heroicons-generator)",
		"slog_logging":              "Slog (Journalisation Structurée)",
		"air_live_reload":           "Air (Rechargement à Chaud - Dev)",
        "status_ok":                 "OK",
        "footer_text":               "Projet de Démarrage EmbryGo",
        "current_year":              "2024",
	},
}

// GetTranslations returns the translation map for the given language.
// Defaults to English if the language is not found.
func GetTranslations(lang string) map[string]string {
	if trans, ok := TranslationsMap[lang]; ok {
		return trans
	}
	slog.Warn("Language not found in translations, defaulting to English", "requested_lang", lang)
	return TranslationsMap["en"] // Default to English
}

# File: tools/input.css
# ------------------------------------------------------------
@tailwind base;
@tailwind components;
@tailwind utilities;

/* Custom base styles or component overrides can go here if needed */

# File: tools/tailwind.config.js
# ------------------------------------------------------------
/** @type {import('tailwindcss').Config} */
module.exports = {
  content: [
    "../webroot/views/**/*.templ", // Scan .templ files for Tailwind classes
    "../webroot/sources/**/*.js",  // Scan source JS if you use Tailwind classes there
  ],
  theme: {
    extend: {},
  },
  plugins: [
    require("@tailwindcss/typography"), // For 'prose' class styling
    require("daisyui"),
  ],
  daisyui: {
    themes: ["light", "night"], // Available themes
    darkTheme: "night",       // Default dark theme
    base: true,               // Applies DaisyUI base styles
    styled: true,             // Applies DaisyUI component styles
    utils: true,              // Applies DaisyUI utility classes
    logs: true,               // Show DaisyUI logs in console (dev only)
  },
}

# File: webroot/sources/app.js
# ------------------------------------------------------------
/**
 * @file webroot/sources/app.js
 * @description Main client-side JavaScript for EmbryGo.
 *              Includes HTMX CSRF configuration.
 */

/**
 * Configures HTMX to automatically include the CSRF token in relevant requests.
 * Reads the token from a meta tag named 'csrf-token'.
 */
function configureHtmxCsrf() {
    const meta = document.querySelector('meta[name="csrf-token"]');
    let token = null;
    if (meta) {
        token = meta.getAttribute('content');
    }

    if (token && token !== "csrf-disabled" && token !== "csrf-api-excluded") {
        document.body.addEventListener('htmx:configRequest', function(event) {
            const method = event.detail.verb.toUpperCase();
            // Add CSRF token for state-changing HTTP methods
            if (method === 'POST' || method === 'PUT' || method === 'DELETE' || method === 'PATCH') {
                event.detail.headers['X-CSRF-Token'] = token;
                // console.debug("CSRF token added to HTMX request:", method, event.detail.path);
            }
        });
        console.info("HTMX CSRF protection configured.");
    } else {
        if (token === "csrf-disabled") {
            console.warn("HTMX CSRF protection explicitly disabled by server config for this page/context.");
        } else if (token === "csrf-api-excluded") {
             console.info("HTMX CSRF protection not applied as this route is likely an API excluded from CSRF.");
        } else {
            console.warn("CSRF token meta tag not found or token is empty. HTMX CSRF protection may not be active.");
        }
    }
}

document.addEventListener('DOMContentLoaded', () => {
    console.log("EmbryGo app.js loaded.");
    configureHtmxCsrf();
    // Add any other client-side initializations here
});

# File: webroot/views/layouts/base.templ
# ------------------------------------------------------------
package layouts

import "strings"
import "net/url"
import "time"
// import "github.com/r-via/embrygo/pkg/translations" // Translations are in BaseData

type BaseData struct {
	Lang         string
	PageTitle    string
	Translations map[string]string
	CSRFToken    string
	BasePath     string
}

func assetUrl(basePath, assetPath string) string {
	if !strings.HasPrefix(assetPath, "/") {
		assetPath = "/" + assetPath
	}
	if basePath == "/" {
		return assetPath
	}
	finalPath, _ := url.JoinPath(basePath, assetPath)
    if !strings.HasPrefix(finalPath, "/") && basePath != "/" {
        //
    } else if basePath == "/" && !strings.HasPrefix(finalPath, "/") {
         return "/" + finalPath
    }
	return finalPath
}

templ Base(data BaseData) {
	<!DOCTYPE html>
	<html lang={data.Lang} class="h-full antialiased" data-theme="night"> {/* Default to night theme */}
		<head>
			<meta charset="UTF-8"/>
			<meta name="viewport" content="width=device-width, initial-scale=1.0"/>
			if data.CSRFToken != "" && data.CSRFToken != "csrf-disabled" {
				<meta name="csrf-token" content={data.CSRFToken}/>
			}
			<title>{data.PageTitle}</title>
			<link href={assetUrl(data.BasePath, "/favicon.ico")} rel="icon" type="image/x-icon"/>
			<link href={assetUrl(data.BasePath, "/tailwind.css")} rel="stylesheet"/>
			<script src={assetUrl(data.BasePath, "/htmx.min.js")} defer></script>
			<script src={assetUrl(data.BasePath, "/app.js")} defer></script>
		</head>
		<body class="min-h-screen bg-base-200 text-base-content flex flex-col">
			<header class="bg-base-300 shadow-md sticky top-0 z-50">
				<div class="container mx-auto px-4 py-4">
					<h1 class="text-2xl font-bold text-primary">
						<a href={assetUrl(data.BasePath, "/welcome")}>{data.Translations["welcome_title"]}</a>
					</h1>
				</div>
			</header>

			<main id="main-content" class="container mx-auto px-4 py-8 flex-grow">
				{children...}
			</main>

			<footer class="bg-base-300 text-base-content/70 text-center py-6 mt-auto">
				<p>© {time.Now().Format("2006")} {data.Translations["footer_text"]}. All rights reserved.</p>
			</footer>
		</body>
	</html>
}

# File: webroot/views/pages/welcome.templ
# ------------------------------------------------------------
package pages

import (
	"github.com/r-via/embrygo/webroot/views/layouts"
	"github.com/r-via/embrygo/webroot/views/components/heroicons" // Assuming heroicons package will be generated here
    "html/template" // For Raw HTML if needed, or just use templ syntax
)

// UtilityStatus represents the status of a core technology/feature.
type UtilityStatus struct {
	Name   string
	Status string
	Icon   string // Name of the Heroicon component (e.g., "Outline_check_circle")
}

// WelcomePageData holds all data needed for the welcome page.
type WelcomePageData struct {
	Lang         string
	Translations map[string]string
	Base         layouts.BaseData
	Utilities    []UtilityStatus
}

// Helper function to render an icon if its name is provided.
func renderIcon(iconName string) templ.Component {
    switch iconName {
        case "check_circle":
            return heroicons.Outline_check_circle(templ.Attributes{"class": "w-5 h-5 mr-3 text-success flex-shrink-0"})
        case "information_circle":
            return heroicons.Outline_information_circle(templ.Attributes{"class": "w-5 h-5 mr-3 text-info flex-shrink-0"})
        // Add more cases for other icons if needed
        default:
            // Return an empty component or a default icon if name is unknown
            return templ.Raw("") 
    }
}


templ WelcomePageContent(data WelcomePageData) {
	<div class="prose max-w-4xl mx-auto bg-base-100 p-6 md:p-8 rounded-lg shadow-lg">
		<h2 class="text-3xl font-semibold mb-6 text-center border-b border-base-300 pb-4">{ data.Translations["welcome_message"] }</h2>
		
		<p class="text-lg">
			This page demonstrates the basic setup of the EmbryGo starter project. 
			It integrates several modern web technologies to provide a solid foundation for your Go applications.
		</p>

		<h3 class="text-2xl font-semibold mt-8 mb-4">{ data.Translations["utilities_title"] }</h3>
		<ul class="list-none p-0 space-y-3">
			for _, util := range data.Utilities {
				<li class="flex items-center py-3 px-4 bg-base-200 rounded-md shadow-sm hover:shadow-md transition-shadow">
                    @renderIcon(util.Icon)
					<span class="font-medium text-base-content flex-grow">{ data.Translations[util.Name] }</span>
					<span class="font-semibold text-success ml-4 badge badge-success badge-outline">{ data.Translations["status_ok"] }</span>
				</li>
			}
		</ul>
        
        <div class="mt-10 p-4 bg-base-200 rounded-md text-sm">
            <p>
                <strong class="text-info">Next Steps:</strong>
            </p>
            <ul class="list-disc list-inside ml-4 mt-2 space-y-1">
                <li>Explore the <code class="bg-base-300 px-1 rounded">Makefile</code> for common commands like <code>make run</code> or <code>make build</code>.</li>
                <li>Check your <code>.env</code> file (created from <code>.env.example</code>) for configuration.</li>
                <li>The BlitzKit server exposes <code>/metrics</code> (Prometheus) and <code>/health</code> endpoints.</li>
                <li>An example admin route is at <code>/admin-example</code> (if <code>ADMIN_USER</code>/<code>PASS</code> are set in <code>.env</code>).</li>
            </ul>
        </div>
	</div>
}

// WelcomePage is the main component for the welcome page, embedding the content within the base layout.
templ WelcomePage(data WelcomePageData) {
	@layouts.Base(data.Base) {
		@WelcomePageContent(data)
	}
}


# --- Content from Go Packages ---

# --- Package: github.com/r-via/blitzkit ---

# File: package:github.com/r-via/blitzkit/cache.go
# ------------------------------------------------------------
// File: cache.go
// Description: Gère la mise en cache à deux niveaux (L1 en mémoire, L2 sur disque via BadgerDB).
//
//	Inclut l'initialisation, la fermeture, la gestion du cycle de vie (GC)
//	et l'adaptation du logger BadgerDB à slog.
package blitzkit

import (
	"errors"
	"fmt"
	"log/slog"
	"sync"
	"time"

	"github.com/dgraph-io/badger/v4"
	cache "github.com/patrickmn/go-cache"
)

// CacheEntry définit la structure stockée dans le cache L1/L2.
// Contient les données binaires, l'heure de dernière modification et l'heure d'expiration.
type CacheEntry struct {
	Data         []byte `json:"data"`
	LastModified int64  `json:"last_modified"`
	ExpiresAt    int64  `json:"expires_at"`
}

// Cache contient les pointeurs vers les caches L1 (en mémoire) et L2 (BadgerDB),
// ainsi que les éléments de contrôle pour le garbage collector (GC) de BadgerDB.
type Cache struct {
	L1 *cache.Cache
	L2 *badger.DB

	stopGC chan struct{}
	gcWG   sync.WaitGroup
}

// badgerSlogAdapter adapte slog.Logger à l'interface logger de BadgerDB.
type badgerSlogAdapter struct {
	logger *slog.Logger
}

// NewCache initialise les systèmes de cache L1 (go-cache) et L2 (BadgerDB).
// Configure les intervalles de nettoyage/GC et démarre la goroutine GC pour BadgerDB si activée.
// Retourne une erreur si l'initialisation de BadgerDB échoue.
//
// Args:
//
//	cacheDir (string): Le chemin du répertoire pour stocker la base de données BadgerDB (L2). Si vide, L2 est désactivé.
//	logger (*slog.Logger): Le logger structuré à utiliser.
//	cleanupInterval (time.Duration): L'intervalle de nettoyage pour le cache L1 (go-cache).
//	gcInterval (time.Duration): L'intervalle pour exécuter le GC du journal de valeurs de BadgerDB (L2). Si <= 0, le GC périodique est désactivé.
//	discardRatio (float64): Le ratio pour le GC de BadgerDB (généralement 0.5).
//
// Returns:
//
//	(*Cache, error): Une instance de Cache initialisée et une erreur nil, ou nil et une erreur en cas d'échec.
func NewCache(
	cacheDir string,
	logger *slog.Logger,
	cleanupInterval time.Duration,
	gcInterval time.Duration,
	discardRatio float64,
) (*Cache, error) {
	if logger == nil {
		logger = slog.Default()
		logger.Warn("NewCache using default logger.")
	}
	logger.Debug("Initializing caches...")

	if cleanupInterval <= 0 {
		cleanupInterval = 10 * time.Minute
	}
	l1 := cache.New(cache.NoExpiration, cleanupInterval)
	logger.Debug("L1 cache initialized.", "cleanupInterval", cleanupInterval)

	var l2 *badger.DB
	var stopGCChan chan struct{}
	cacheInstance := &Cache{L1: l1, L2: nil}

	if cacheDir != "" {
		logger.Debug("Attempting L2 cache init", "path", cacheDir)
		opts := badger.DefaultOptions(cacheDir).
			WithLoggingLevel(badger.WARNING).
			WithLogger(&badgerSlogAdapter{logger: logger})

		var errL2 error
		l2, errL2 = badger.Open(opts)
		if errL2 != nil {
			logger.Error("Failed to open BadgerDB for L2 cache, L2 disabled.", "path", cacheDir, "error", errL2)
			l2 = nil
		} else {
			logger.Info("L2 cache (BadgerDB) initialized", "path", cacheDir)
			cacheInstance.L2 = l2

			if gcInterval > 0 {
				logger.Info("Starting periodic BadgerDB GC", "interval", gcInterval, "discard_ratio", discardRatio)
				stopGCChan = make(chan struct{})
				cacheInstance.stopGC = stopGCChan
				cacheInstance.gcWG.Add(1)
				go runBadgerGC(l2, logger, stopGCChan, gcInterval, discardRatio, &cacheInstance.gcWG)
			} else {
				logger.Info("Periodic BadgerDB GC disabled by configuration.")
			}
		}
	} else {
		logger.Warn("CacheDir not configured, L2 cache disabled.")
	}

	return cacheInstance, nil
}

// Close arrête proprement la goroutine GC de BadgerDB (si elle existe)
// et ferme la connexion à la base de données BadgerDB (L2).
//
// Args:
//
//	logger (*slog.Logger): Le logger structuré à utiliser.
//
// Returns:
//
//	error: Une erreur si la fermeture de BadgerDB échoue, sinon nil.
func (c *Cache) Close(logger *slog.Logger) error {
	log := logger
	if log == nil {
		log = slog.Default()
	}

	if c.stopGC != nil {
		log.Info("Stopping BadgerDB GC goroutine...")
		select {
		case <-c.stopGC:
			log.Warn("BadgerDB GC stop channel already closed.")
		default:
			close(c.stopGC)
		}
		c.gcWG.Wait()
		log.Info("BadgerDB GC goroutine stopped.")
		c.stopGC = nil
	} else {
		log.Debug("BadgerDB GC goroutine was not running.")
	}

	if c.L2 == nil {
		log.Debug("L2 cache was nil, skipping close.")
		return nil
	}
	log.Debug("Closing L2 cache (BadgerDB)...")
	err := c.L2.Close()
	if err != nil {
		log.Error("Failed to close BadgerDB", "error", err)
		return fmt.Errorf("failed to close L2 cache: %w", err)
	}
	log.Info("L2 cache closed successfully.")
	return nil
}

// Errorf implémente la méthode Errorf de l'interface badger.Logger.
// Transmet le message formaté au logger slog sous-jacent au niveau Error.
func (bsa *badgerSlogAdapter) Errorf(format string, args ...interface{}) {
	if bsa.logger != nil {
		bsa.logger.Error(fmt.Sprintf(format, args...))
	}
}

// Warningf implémente la méthode Warningf de l'interface badger.Logger.
// Transmet le message formaté au logger slog sous-jacent au niveau Warn.
func (bsa *badgerSlogAdapter) Warningf(format string, args ...interface{}) {
	if bsa.logger != nil {
		bsa.logger.Warn(fmt.Sprintf(format, args...))
	}
}

// Infof implémente la méthode Infof de l'interface badger.Logger.
// Transmet le message formaté au logger slog sous-jacent au niveau Debug (car Badger Info est souvent verbeux).
func (bsa *badgerSlogAdapter) Infof(format string, args ...interface{}) {
	if bsa.logger != nil {
		bsa.logger.Debug(fmt.Sprintf(format, args...))
	}
}

// Debugf implémente la méthode Debugf de l'interface badger.Logger.
// Transmet le message formaté au logger slog sous-jacent au niveau Debug.
func (bsa *badgerSlogAdapter) Debugf(format string, args ...interface{}) {
	if bsa.logger != nil {
		bsa.logger.Debug(fmt.Sprintf(format, args...))
	}
}

// runBadgerGC est la fonction exécutée par la goroutine de garbage collection de BadgerDB.
// Elle exécute périodiquement `db.RunValueLogGC` à l'intervalle spécifié et s'arrête
// lorsque le canal `stopChan` est fermé.
//
// Args:
//
//	db (*badger.DB): La connexion à la base de données BadgerDB sur laquelle exécuter le GC.
//	logger (*slog.Logger): Le logger pour enregistrer les événements du GC.
//	stopChan (chan struct{}): Le canal utilisé pour signaler l'arrêt de la goroutine.
//	gcInterval (time.Duration): L'intervalle entre les exécutions du GC.
//	discardRatio (float64): Le ratio de discard pour le GC.
//	wg (*sync.WaitGroup): Le WaitGroup à notifier lorsque la goroutine se termine.
func runBadgerGC(db *badger.DB, logger *slog.Logger, stopChan chan struct{}, gcInterval time.Duration, discardRatio float64, wg *sync.WaitGroup) {
	defer wg.Done()

	if db == nil || logger == nil || stopChan == nil || wg == nil {
		println("FATAL: nil parameter(s) passed to runBadgerGC")
		return
	}

	ticker := time.NewTicker(gcInterval)
	defer ticker.Stop()

	logger.Debug("BadgerDB GC goroutine started", "interval", gcInterval, "ratio", discardRatio)

	for {
		select {
		case <-ticker.C:
			logCtx := logger.With(slog.Float64("discard_ratio", discardRatio))
			logCtx.Info("Running periodic BadgerDB Value Log GC task...")
			startTime := time.Now()
			runCount := 0

			for {
				runCount++
				gcErr := db.RunValueLogGC(discardRatio)
				if errors.Is(gcErr, badger.ErrNoRewrite) {
					logCtx.Info("No rewrite needed during BadgerDB GC", "iterations", runCount)
					break
				}
				if gcErr != nil {
					logCtx.Error("Error during BadgerDB RunValueLogGC iteration", "iteration", runCount, "error", gcErr)
					break
				}
			}

			duration := time.Since(startTime)
			logCtx.Info("BadgerDB GC task completed", "duration", duration, "iterations", runCount)

		case <-stopChan:
			logger.Info("BadgerDB GC goroutine received stop signal. Exiting.")
			return
		}
	}
}


# File: package:github.com/r-via/blitzkit/cache_methods.go
# ------------------------------------------------------------
// File: cache_methods.go
// Description: Contient les méthodes du serveur web pour interagir avec le système de cache.
//
//	Inclut le rendu de pages HTML (templ) et de données binaires via le cache,
//	l'invalidation et le vidage du cache.
package blitzkit

import (
	"bytes"
	"encoding/json"
	"errors"
	"fmt"
	"log/slog"
	"net/http"
	"time"

	"github.com/dgraph-io/badger/v4"
	"github.com/gofiber/fiber/v2"
	cache "github.com/patrickmn/go-cache"
)

// RenderPage effectue le rendu d'une page HTML (générée par une fonction `PageGeneratorFunc`)
// en utilisant le système de cache L1/L2.
// 1. Tente de récupérer depuis L1.
// 2. Si absent ou invalide, tente de récupérer depuis L2.
// 3. Si L2 trouvé et valide, le charge dans L1 et sert le contenu.
// 4. Si L2 absent ou expiré, appelle `generatorFunc`, stocke le résultat dans L1 et L2, et sert le contenu généré.
// Définit l'en-tête `X-Cache-Status` (HIT-L1, HIT-L2, MISS) et `Content-Type`.
//
// Args:
//
//	ctx (interface{}): Le contexte de la requête, attendu comme *fiber.Ctx.
//	key (string): La clé unique identifiant cette page dans le cache.
//	ttlInfo (CacheTTLInfo): Informations sur la durée de vie du cache (infini ou par défaut).
//	generatorFunc (PageGeneratorFunc): La fonction qui génère le composant `templ.Component` et le timestamp lastModified si le cache est manquant.
//
// Returns:
//
//	error: Une erreur si le type de contexte est invalide, si la génération échoue,
//	       si le rendu échoue, ou si l'envoi de la réponse échoue. Gérée par l'ErrorHandler de Fiber.
func (s *Server) RenderPage(ctx interface{}, key string, ttlInfo CacheTTLInfo, generatorFunc PageGeneratorFunc) error {
	c, ok := ctx.(*fiber.Ctx)
	if !ok {
		s.logger.Error("Invalid context type for RenderPage", "expected", "*fiber.Ctx", "received", fmt.Sprintf("%T", ctx))
		return fiber.NewError(http.StatusInternalServerError, "Internal server error (invalid context type in RenderPage)")
	}
	logCtx := s.logger.With(slog.String("cache_key", key), slog.String("path", c.Path()))

	if s.Cache != nil && s.Cache.L1 != nil {
		if cachedItem, found := s.Cache.L1.Get(key); found {
			IncCacheL1Hit()
			if dataBytes, ok := cachedItem.([]byte); ok {
				if s.config.DevMode {
					logCtx.Debug("Cache L1 hit")
				}
				c.Set(HeaderCacheStatus, "HIT-L1")
				c.Set(fiber.HeaderContentType, fiber.MIMETextHTMLCharsetUTF8)
				return c.Send(dataBytes)
			}
			logCtx.Warn("Cache L1 hit but invalid data type found, deleting", "type", fmt.Sprintf("%T", cachedItem))
			s.Cache.L1.Delete(key)
		} else {
			IncCacheL1Miss()
			if s.config.DevMode {
				logCtx.Debug("Cache L1 miss")
			}
		}
	} else {
		logCtx.Warn("L1 cache not available for RenderPage lookup")
	}

	var cacheEntry CacheEntry
	foundInL2 := false
	if s.Cache != nil && s.Cache.L2 != nil {
		errL2 := s.Cache.L2.View(func(txn *badger.Txn) error {
			item, err := txn.Get([]byte(key))
			if err != nil {
				return err
			}
			return item.Value(func(val []byte) error {
				if err := json.Unmarshal(val, &cacheEntry); err != nil {
					logCtx.Warn("Failed to unmarshal L2 cache entry, treating as miss", "error", err)
					return nil
				}
				foundInL2 = true
				return nil
			})
		})
		if errL2 != nil && !errors.Is(errL2, badger.ErrKeyNotFound) {
			logCtx.Error("Error during L2 cache View", "error", errL2)
			foundInL2 = false
			IncCacheL2Miss()
		} else if errors.Is(errL2, badger.ErrKeyNotFound) {
			IncCacheL2Miss()
		} else if foundInL2 {
			IncCacheL2Hit()
		}
	} else {
		if s.config.DevMode {
			logCtx.Debug("L2 Cache not available for RenderPage lookup")
		}
	}

	now := time.Now().Unix()
	if foundInL2 {
		isExpired := cacheEntry.ExpiresAt != 0 && cacheEntry.ExpiresAt <= now
		if !isExpired {
			if s.config.DevMode {
				logCtx.Debug("Cache L2 hit (valid)")
			}
			if s.Cache != nil && s.Cache.L1 != nil {
				l1TTL := s.config.CacheL1DefaultTTL
				if ttlInfo.IsInfinite {
					l1TTL = cache.NoExpiration
				}
				s.Cache.L1.Set(key, cacheEntry.Data, l1TTL)
				IncCacheL1LoadedFromL2()
				if s.config.DevMode {
					logCtx.Debug("Loaded L2 content into L1", "l1_ttl", l1TTL)
				}
			}
			c.Set(HeaderCacheStatus, "HIT-L2")
			c.Set(fiber.HeaderContentType, fiber.MIMETextHTMLCharsetUTF8)
			return c.Send(cacheEntry.Data)
		}
		if s.config.DevMode {
			logCtx.Debug("Cache L2 hit but expired", "expires_at", time.Unix(cacheEntry.ExpiresAt, 0))
		}
	} else if s.Cache != nil && s.Cache.L2 != nil {
		if s.config.DevMode {
			logCtx.Debug("Cache L2 miss or entry invalid/expired")
		}
	}

	if generatorFunc == nil {
		logCtx.Error("Page generator function is nil")
		return fiber.NewError(http.StatusInternalServerError, fmt.Sprintf("nil generator for key %s", key))
	}

	if s.config.DevMode {
		logCtx.Debug("Generating page content")
	}
	generationStart := time.Now()
	component, lastModified, errGen := generatorFunc()
	generationDuration := time.Since(generationStart)
	ObservePageGenerationDuration(generationDuration.Seconds(), key)

	if errGen != nil {
		var fe *fiber.Error
		if errors.As(errGen, &fe) {
			logCtx.Warn("Generator returned fiber error", "status", fe.Code, "error", fe.Message)
			return fe
		}
		logCtx.Error("Page generator failed", "error", errGen, "duration", generationDuration)
		return fiber.NewError(http.StatusInternalServerError, fmt.Sprintf("page generator failed for key %s", key))
	}
	if component == nil {
		logCtx.Error("Page generator returned nil component")
		return fiber.NewError(http.StatusInternalServerError, fmt.Sprintf("generator returned nil component for %s", key))
	}

	var buf bytes.Buffer
	if errRender := component.Render(c.Context(), &buf); errRender != nil {
		logCtx.Error("Failed to render templ component after generation", "error", errRender)
		return fiber.NewError(http.StatusInternalServerError, "Failed to render generated component")
	}
	generatedBytes := buf.Bytes()

	if s.Cache != nil {
		if s.Cache.L1 != nil {
			l1TTL := s.config.CacheL1DefaultTTL
			if ttlInfo.IsInfinite {
				l1TTL = cache.NoExpiration
			}
			s.Cache.L1.Set(key, generatedBytes, l1TTL)
			IncCacheL1Set()
			if s.config.DevMode {
				logCtx.Debug("Stored generated content in L1", "l1_ttl", l1TTL)
			}
		}
		if s.Cache.L2 != nil {
			errStore := s.storeInL2(key, CacheEntry{Data: generatedBytes, LastModified: lastModified}, ttlInfo.IsInfinite)
			if errStore != nil {
				logCtx.Error("Failed to store generated content in L2", "error", errStore)
			}
		}
	}

	c.Set(HeaderCacheStatus, "MISS")
	c.Set(fiber.HeaderContentType, fiber.MIMETextHTMLCharsetUTF8)
	return c.Send(generatedBytes)
}

// RenderBytesPage effectue le rendu de données binaires (ex: XML, CSS, JS)
// (générées par une fonction `BytesGeneratorFunc`) en utilisant le système de cache L1/L2.
// La logique est similaire à `RenderPage`, mais travaille directement avec des slices de bytes.
// Définit l'en-tête `X-Cache-Status` et le `Content-Type` fourni.
//
// Args:
//
//	ctx (interface{}): Le contexte de la requête, attendu comme *fiber.Ctx.
//	key (string): La clé unique identifiant ces données dans le cache.
//	contentType (string): Le type MIME à définir dans l'en-tête Content-Type de la réponse.
//	ttlInfo (CacheTTLInfo): Informations sur la durée de vie du cache (infini ou par défaut).
//	generatorFunc (BytesGeneratorFunc): La fonction qui génère la slice de bytes et le timestamp lastModified si le cache est manquant.
//
// Returns:
//
//	error: Une erreur si le type de contexte est invalide, si la génération échoue,
//	       ou si l'envoi de la réponse échoue. Gérée par l'ErrorHandler de Fiber.
func (s *Server) RenderBytesPage(ctx interface{}, key string, contentType string, ttlInfo CacheTTLInfo, generatorFunc BytesGeneratorFunc) error {
	c, ok := ctx.(*fiber.Ctx)
	if !ok {
		s.logger.Error("Invalid context type for RenderBytesPage", "expected", "*fiber.Ctx", "received", fmt.Sprintf("%T", ctx))
		return fiber.NewError(http.StatusInternalServerError, "Internal server error (invalid context type in RenderBytesPage)")
	}
	logCtx := s.logger.With(slog.String("cache_key", key), slog.String("path", c.Path()), slog.String("content_type", contentType))

	if s.Cache != nil && s.Cache.L1 != nil {
		if cachedItem, found := s.Cache.L1.Get(key); found {
			IncCacheL1Hit()
			if dataBytes, ok := cachedItem.([]byte); ok {
				if s.config.DevMode {
					logCtx.Debug("Cache L1 hit (bytes)")
				}
				c.Set(HeaderCacheStatus, "HIT-L1")
				c.Set(fiber.HeaderContentType, contentType)
				return c.Send(dataBytes)
			}
			logCtx.Warn("Cache L1 hit (bytes) but invalid data type found, deleting", "type", fmt.Sprintf("%T", cachedItem))
			s.Cache.L1.Delete(key)
		} else {
			IncCacheL1Miss()
			if s.config.DevMode {
				logCtx.Debug("Cache L1 miss (bytes)")
			}
		}
	} else {
		logCtx.Warn("L1 cache not available for RenderBytesPage lookup")
	}

	var cacheEntry CacheEntry
	foundInL2 := false
	if s.Cache != nil && s.Cache.L2 != nil {
		errL2 := s.Cache.L2.View(func(txn *badger.Txn) error {
			item, err := txn.Get([]byte(key))
			if err != nil {
				return err
			}
			return item.Value(func(val []byte) error {
				if err := json.Unmarshal(val, &cacheEntry); err != nil {
					logCtx.Warn("Failed L2 unmarshal (bytes)", "error", err)
					return nil
				}
				foundInL2 = true
				return nil
			})
		})
		if errL2 != nil && !errors.Is(errL2, badger.ErrKeyNotFound) {
			logCtx.Error("Error during L2 cache View (bytes)", "error", errL2)
			foundInL2 = false
			IncCacheL2Miss()
		} else if errors.Is(errL2, badger.ErrKeyNotFound) {
			IncCacheL2Miss()
		} else if foundInL2 {
			IncCacheL2Hit()
		}
	} else {
		if s.config.DevMode {
			logCtx.Debug("L2 Cache not available for RenderBytesPage lookup")
		}
	}

	now := time.Now().Unix()
	if foundInL2 {
		isExpired := cacheEntry.ExpiresAt != 0 && cacheEntry.ExpiresAt <= now
		if !isExpired {
			if s.config.DevMode {
				logCtx.Debug("Cache L2 hit (valid) (bytes)")
			}
			if s.Cache != nil && s.Cache.L1 != nil {
				l1TTL := s.config.CacheL1DefaultTTL
				if ttlInfo.IsInfinite {
					l1TTL = cache.NoExpiration
				}
				s.Cache.L1.Set(key, cacheEntry.Data, l1TTL)
				IncCacheL1LoadedFromL2()
				if s.config.DevMode {
					logCtx.Debug("Loaded L2 bytes into L1", "l1_ttl", l1TTL)
				}
			}
			c.Set(HeaderCacheStatus, "HIT-L2")
			c.Set(fiber.HeaderContentType, contentType)
			return c.Send(cacheEntry.Data)
		}
		if s.config.DevMode {
			logCtx.Debug("Cache L2 hit but expired (bytes)")
		}
	} else if s.Cache != nil && s.Cache.L2 != nil {
		if s.config.DevMode {
			logCtx.Debug("Cache L2 miss or entry invalid/expired (bytes)")
		}
	}

	if generatorFunc == nil {
		logCtx.Error("Byte generator function is nil")
		return fiber.NewError(http.StatusInternalServerError, fmt.Sprintf("nil generator for key %s", key))
	}

	generationStart := time.Now()
	generatedBytes, lastModified, errGen := generatorFunc()
	generationDuration := time.Since(generationStart)
	ObservePageGenerationDuration(generationDuration.Seconds(), key)
	if errGen != nil {
		logCtx.Error("Byte generator function failed", "error", errGen, "duration", generationDuration)
		return fiber.NewError(http.StatusInternalServerError, fmt.Sprintf("byte generator failed for key %s", key))
	}
	if generatedBytes == nil {
		logCtx.Error("Byte generator returned nil data")
		return fiber.NewError(http.StatusInternalServerError, fmt.Sprintf("generator returned nil data for %s", key))
	}

	if s.Cache != nil {
		if s.Cache.L1 != nil {
			l1TTL := s.config.CacheL1DefaultTTL
			if ttlInfo.IsInfinite {
				l1TTL = cache.NoExpiration
			}
			s.Cache.L1.Set(key, generatedBytes, l1TTL)
			IncCacheL1Set()
			if s.config.DevMode {
				logCtx.Debug("Stored generated bytes in L1", "l1_ttl", l1TTL)
			}
		}
		if s.Cache.L2 != nil {
			errStore := s.storeInL2(key, CacheEntry{Data: generatedBytes, LastModified: lastModified}, ttlInfo.IsInfinite)
			if errStore != nil {
				logCtx.Error("Failed to store generated bytes in L2 cache", "error", errStore)
			}
		}
	}

	c.Set(HeaderCacheStatus, "MISS")
	c.Set(fiber.HeaderContentType, contentType)
	return c.Send(generatedBytes)
}

// Invalidate supprime une clé spécifique des caches L1 et L2.
// Logue les informations sur l'opération et les éventuelles erreurs de suppression L2.
// Incrémente les compteurs Prometheus correspondants.
//
// Args:
//
//	key (string): La clé de cache à invalider.
//
// Returns:
//
//	error: Retourne la première erreur rencontrée lors de la suppression L2, ou nil si l'opération réussit.
func (s *Server) Invalidate(key string) error {
	if s.Cache == nil {
		s.logger.Warn("Invalidate called but cache is nil", slog.String("cache_key", key))
		return nil
	}
	logCtx := s.logger.With(slog.String("cache_key", key))
	logCtx.Info("Invalidating cache key")
	var firstError error

	if s.Cache.L1 != nil {
		s.Cache.L1.Delete(key)
		if s.config.DevMode {
			logCtx.Debug("Removed key from L1 cache")
		}
	}

	if s.Cache.L2 != nil {
		errL2 := s.Cache.L2.Update(func(txn *badger.Txn) error {
			err := txn.Delete([]byte(key))
			if err != nil && !errors.Is(err, badger.ErrKeyNotFound) {
				IncCacheInvalidationErrors()
				return fmt.Errorf("L2 delete failed: %w", err)
			}
			return nil
		})
		if errL2 != nil {
			logCtx.Error("L2 Update operation failed during invalidation", "error", errL2)
			if firstError == nil {
				firstError = errL2
			}
		} else {
			if s.config.DevMode {
				logCtx.Debug("L2 key removed or not found")
			}
		}
	}
	if firstError == nil {
		IncCacheInvalidations()
		if s.config.DevMode {
			logCtx.Debug("Cache invalidation successful or key not found")
		}
	}
	return firstError
}

// Flush vide complètement les caches L1 (mémoire) et L2 (disque - BadgerDB DropAll).
// Cette opération est destructive et supprime toutes les données mises en cache.
// Logue les informations sur l'opération et les éventuelles erreurs.
//
// Returns:
//
//	error: Retourne la première erreur rencontrée lors du vidage L2, ou nil si l'opération réussit.
func (s *Server) Flush() error {
	if s.Cache == nil {
		s.logger.Warn("Flush called but cache is nil")
		return nil
	}
	s.logger.Warn("Flushing ALL caches (L1 and L2)...")
	var firstError error

	if s.Cache.L1 != nil {
		s.Cache.L1.Flush()
		s.logger.Info("Flushed L1 cache.")
	}

	if s.Cache.L2 != nil {
		s.logger.Info("Dropping all data from L2 cache (BadgerDB)...")
		errL2 := s.Cache.L2.DropAll()
		if errL2 != nil {
			s.logger.Error("Failed to flush L2 cache (BadgerDB DropAll)", "error", errL2)
			if firstError == nil {
				firstError = errL2
			}
		} else {
			s.logger.Info("Flushed L2 cache (BadgerDB) successfully.")
		}
	}
	if firstError == nil {
		s.logger.Info("Cache flush completed.")
	} else {
		s.logger.Error("Cache flush completed with errors.", "error", firstError)
	}
	return firstError
}

// storeInL2 stocke une entrée `CacheEntry` dans le cache L2 (BadgerDB).
// L'entrée est d'abord sérialisée en JSON. Le TTL BadgerDB est défini si l'entrée
// n'est pas marquée comme infinie et si le TTL L2 par défaut est positif.
// Logue les erreurs de sérialisation ou de stockage et incrémente les compteurs Prometheus.
//
// Args:
//
//	key (string): La clé sous laquelle stocker l'entrée.
//	entry (CacheEntry): L'entrée de cache à stocker.
//	isInfinite (bool): Indique si l'entrée doit expirer (selon CacheL2DefaultTTL) ou non.
//
// Returns:
//
//	error: Une erreur si la sérialisation JSON ou l'opération BadgerDB `Update` échoue, sinon nil.
func (s *Server) storeInL2(key string, entry CacheEntry, isInfinite bool) error {
	if s.Cache == nil || s.Cache.L2 == nil {
		if s.config.DevMode {
			s.logger.Debug("L2 cache not available, skipping store", slog.String("cache_key", key))
		}
		return nil
	}
	logCtx := s.logger.With(slog.String("cache_key", key))

	var l2TTL time.Duration
	entry.ExpiresAt = 0
	if !isInfinite {
		l2TTL = s.config.CacheL2DefaultTTL
		if l2TTL > 0 {
			entry.ExpiresAt = time.Now().Add(l2TTL).Unix()
		} else {
			isInfinite = true
		}
	}
	if s.config.DevMode {
		logCtx.Debug("Storing in L2", "isInfinite", isInfinite, "expiresAt", entry.ExpiresAt)
	}

	cacheData, err := json.Marshal(entry)
	if err != nil {
		logCtx.Error("Failed marshal cache entry for L2", "error", err)
		IncCacheL2SetErrors()
		return fmt.Errorf("failed marshal entry for %s: %w", key, err)
	}

	err = s.Cache.L2.Update(func(txn *badger.Txn) error {
		badgerEntry := badger.NewEntry([]byte(key), cacheData)
		if !isInfinite && l2TTL > 0 {
			badgerEntry = badgerEntry.WithTTL(l2TTL)
		}
		return txn.SetEntry(badgerEntry)
	})
	if err != nil {
		IncCacheL2SetErrors()
		logCtx.Error("Failed store in L2", "error", err)
		return fmt.Errorf("failed L2 Update for %s: %w", key, err)
	}

	IncCacheL2Set()
	if s.config.DevMode {
		logCtx.Debug("Stored entry in L2 successfully")
	}
	return nil
}


# File: package:github.com/r-via/blitzkit/error_handling.go
# ------------------------------------------------------------
// File: error_handling.go
// Description: Définit le gestionnaire d'erreurs centralisé pour l'application Fiber.
//
//	Il intercepte les erreurs, détermine le code de statut HTTP approprié,
//	logue l'erreur, et renvoie une réponse formatée (HTML via composant Templ, JSON, ou texte brut).
package blitzkit

import (
	"context"
	"errors"
	"fmt"
	"log/slog"

	"github.com/a-h/templ"
	"github.com/gofiber/fiber/v2"
	"github.com/gofiber/fiber/v2/middleware/adaptor"
)

// handleError est le gestionnaire d'erreurs global enregistré auprès de Fiber (via fiber.Config).
// Il est appelé automatiquement par Fiber lorsqu'un handler retourne une erreur ou qu'un panic se produit (si Recover middleware est utilisé).
// Il détermine le code d'erreur et le message, logue l'incident, puis tente de renvoyer une réponse appropriée :
// 1. Composant d'erreur Templ si configuré (`ErrorComponentGenerator`) et si le client accepte HTML.
// 2. Réponse JSON si le client accepte JSON (`Accept: application/json`).
// 3. Message texte brut en dernier recours.
// En mode production, les détails des erreurs 5xx internes sont masqués au client.
//
// Args:
//
//	c (*fiber.Ctx): Le contexte Fiber de la requête ayant échoué.
//	err (error): L'erreur qui s'est produite.
//
// Returns:
//
//	error: Une erreur nil si la réponse d'erreur a été envoyée avec succès, ou une erreur si l'envoi final échoue.
func (s *Server) handleError(c *fiber.Ctx, err error) error {
	code := fiber.StatusInternalServerError
	message := "Internal Server Error"

	var fe *fiber.Error
	if errors.As(err, &fe) {
		code = fe.Code
		message = fe.Message
	} else {
		s.logger.Error("Internal server error", "path", c.Path(), "method", c.Method(),
			"ip", GetClientIP(c.Get(fiber.HeaderXForwardedFor), c.IP()), "error", err)
		if s.config.DevMode {
			message = fmt.Sprintf("%s: %v", message, err)
		}
	}

	logLevel := slog.LevelWarn
	if code >= 500 {
		logLevel = slog.LevelError
	}
	s.logger.Log(context.Background(), logLevel, "Request error handled",
		"code", code, "message", message, "path", c.Path(), "method", c.Method(),
		"ip", GetClientIP(c.Get(fiber.HeaderXForwardedFor), c.IP()), "original_error_type", fmt.Sprintf("%T", err))

	c.Status(code)

	clientWantsJSON := WantsJSON(c)

	if s.config.ErrorComponentGenerator != nil && !clientWantsJSON {
		errorComponent := s.config.ErrorComponentGenerator(err, code, s.config.DevMode)
		if errorComponent != nil {
			renderErr := adaptor.HTTPHandler(templ.Handler(errorComponent))(c)
			if renderErr == nil {
				return nil
			}
			s.logger.Error("Failed to render error component, falling back", "code", code, "render_error", renderErr)
		}
	}

	if clientWantsJSON {
		errorMsgJson := message
		if code >= 500 && !s.config.DevMode {
			errorMsgJson = "Internal Server Error"
		}
		return c.JSON(fiber.Map{"error": errorMsgJson})
	}

	finalMessage := fmt.Sprintf("%d: %s", code, message)

	return c.SendString(finalMessage)
}


# File: package:github.com/r-via/blitzkit/middleware.go
# ------------------------------------------------------------
// File: middleware.go
// Description: Contient la configuration et l'enregistrement des middlewares de base
//
//	pour l'application Fiber, tels que Recover, CORS, les en-têtes de sécurité,
//	et la journalisation des requêtes.
package blitzkit

import (
	"context"
	"log/slog"
	"time"

	"github.com/gofiber/fiber/v2"
	"github.com/gofiber/fiber/v2/middleware/cors"
	"github.com/gofiber/fiber/v2/middleware/recover"
)

// setupBaseMiddlewares configure et enregistre les middlewares fondamentaux pour l'instance Fiber.
// Ceci inclut Recover, CORS (configuré via des variables d'environnement),
// l'ajout d'en-têtes de sécurité (définis dans la configuration), la journalisation des requêtes,
// et tout middleware personnalisé fourni dans la configuration.
func (s *Server) setupBaseMiddlewares() {
	s.logger.Debug("Setting up base middlewares...")

	s.app.Use(recover.New(recover.Config{
		EnableStackTrace: s.config.DevMode,
	}))
	s.logger.Debug("Added Recover middleware.")

	corsConfig := cors.Config{
		AllowMethods:     "GET,POST,PUT,DELETE,PATCH,HEAD,OPTIONS",
		AllowHeaders:     "Origin,Content-Type,Accept,Authorization,X-CSRF-Token,HX-Request,HX-Trigger,HX-Target,HX-Current-URL,Content-Length,X-Api-Key",
		ExposeHeaders:    "Content-Length,HX-Location,HX-Redirect,HX-Refresh,HX-Retarget,HX-Reswap,HX-Trigger,HX-Trigger-After-Settle,HX-Trigger-After-Swap",
		AllowCredentials: true,
		MaxAge:           86400,
	}
	allowedOrigins := getEnvOrDefault(s.logger, "CORS_ALLOW_ORIGINS", "", "")
	if s.config.DevMode {
		if allowedOrigins == "" {
			allowedOrigins = "*"
			if corsConfig.AllowCredentials {
				s.logger.Error("FATAL: Insecure CORS dev setup: AllowOrigins='*' with AllowCredentials=true. Set CORS_ALLOW_ORIGINS or disable credentials.")
				panic("Insecure CORS dev setup")
			}
		}
	} else {
		if allowedOrigins == "" || (allowedOrigins == "*" && corsConfig.AllowCredentials) {
			s.logger.Error("FATAL: Invalid CORS production config (CORS_ALLOW_ORIGINS missing or '*' with credentials)")
			panic("Invalid CORS production config")
		}
	}
	corsConfig.AllowOrigins = allowedOrigins
	s.app.Use(cors.New(corsConfig))
	s.logger.Info("Added CORS middleware.", "applied_origins", allowedOrigins, "allow_credentials", corsConfig.AllowCredentials)

	if len(s.config.SecurityHeaders) > 0 {
		s.app.Use(func(c *fiber.Ctx) error {
			for key, value := range s.config.SecurityHeaders {
				c.Set(key, value)
			}
			return c.Next()
		})
		s.logger.Info("Added Security Headers middleware.", "count", len(s.config.SecurityHeaders))
	}

	s.app.Use(s.logRequests)
	s.logger.Debug("Added Request Logging middleware.")

	for i, mwFunc := range s.config.CustomMiddlewares {
		s.app.Use(mwFunc)
		s.logger.Debug("Added custom middleware from config", "index", i+1)
	}
}

// logRequests est un middleware Fiber qui enregistre les détails de chaque requête traitée.
// Il capture la méthode, le chemin, le statut de la réponse, la durée de traitement,
// l'adresse IP du client, la taille de la réponse, l'agent utilisateur, l'ID de la requête (si disponible),
// et le statut du cache (si défini par `RenderPage`/`RenderBytesPage`). Le niveau de log (Debug, Info, Warn, Error)
// est ajusté en fonction du statut de la réponse et de la présence d'une erreur.
//
// Args:
//
//	c (*fiber.Ctx): Le contexte Fiber de la requête.
//
// Returns:
//
//	error: L'erreur retournée par le prochain middleware ou handler dans la chaîne.
func (s *Server) logRequests(c *fiber.Ctx) error {
	start := time.Now()
	clientIP := GetClientIP(c.Get(fiber.HeaderXForwardedFor), c.IP())

	err := c.Next()

	duration := time.Since(start)
	status := c.Response().StatusCode()

	logLevel := slog.LevelInfo
	if s.config.DevMode && status < 400 && err == nil {
		logLevel = slog.LevelDebug
	}
	if status >= 500 {
		logLevel = slog.LevelError
	} else if status >= 400 {
		logLevel = slog.LevelWarn
	}
	if err != nil && logLevel < slog.LevelError {
		logLevel = slog.LevelError
	}

	attrs := []slog.Attr{
		slog.String("method", c.Method()),
		slog.String("path", c.OriginalURL()),
		slog.Int("status", status),
		slog.Duration("duration_ms", duration.Round(time.Millisecond)),
		slog.String("ip", clientIP),
		slog.Int("resp_size_bytes", len(c.Response().Body())),
	}
	if userAgent := c.Get(fiber.HeaderUserAgent); userAgent != "" {
		attrs = append(attrs, slog.String("user_agent", userAgent))
	}
	reqIDVal := c.Locals("requestid")
	if reqIDStr, ok := reqIDVal.(string); ok && reqIDStr != "" {
		attrs = append(attrs, slog.String("request_id", reqIDStr))
	} else if reqIDHeader := c.Get(fiber.HeaderXRequestID); reqIDHeader != "" {
		attrs = append(attrs, slog.String("request_id", reqIDHeader))
	}

	cacheStatusBytes := c.Response().Header.Peek(HeaderCacheStatus)
	if len(cacheStatusBytes) > 0 {
		attrs = append(attrs, slog.String("cache", string(cacheStatusBytes)))
	}

	if err != nil {
		attrs = append(attrs, slog.String("error", err.Error()))
	}

	s.logger.LogAttrs(context.Background(), logLevel, "Request handled", attrs...)
	return err
}


# File: package:github.com/r-via/blitzkit/monitoring.go
# ------------------------------------------------------------
// File: monitoring.go
// Description: Gère la configuration et l'exposition des métriques Prometheus
//
//	et du point de terminaison de contrôle de santé (/health).
package blitzkit

import (
	"errors"
	"fmt"
	"log/slog"
	"sync/atomic"

	"github.com/ansrivas/fiberprometheus/v2"
	"github.com/dgraph-io/badger/v4"
	"github.com/gofiber/fiber/v2"
	"github.com/prometheus/client_golang/prometheus"
	"github.com/prometheus/client_golang/prometheus/promauto"
)

// --- Prometheus Metrics Definitions ---

// cacheL1Hits: Compteur total des succès du cache L1.
var cacheL1Hits prometheus.Counter

// cacheL1Misses: Compteur total des échecs du cache L1.
var cacheL1Misses prometheus.Counter

// cacheL1Sets: Compteur total des éléments définis dans le cache L1.
var cacheL1Sets prometheus.Counter

// cacheL1LoadedFromL2: Compteur total des éléments chargés dans L1 depuis L2.
var cacheL1LoadedFromL2 prometheus.Counter

// cacheL2Hits: Compteur total des succès du cache L2.
var cacheL2Hits prometheus.Counter

// cacheL2Misses: Compteur total des échecs du cache L2 (inclut non trouvé, erreurs, etc.).
var cacheL2Misses prometheus.Counter

// cacheL2Sets: Compteur total des éléments définis avec succès dans le cache L2.
var cacheL2Sets prometheus.Counter

// cacheL2SetErrors: Compteur total des erreurs lors de la définition d'éléments dans L2.
var cacheL2SetErrors prometheus.Counter

// cacheInvalidations: Compteur total des invalidations de cache réussies.
var cacheInvalidations prometheus.Counter

// cacheInvalidationErrors: Compteur total des erreurs lors de l'invalidation du cache.
var cacheInvalidationErrors prometheus.Counter

// cacheWarmupSkipped: Compteur total des éléments sautés lors du préchauffage du cache (déjà dans L1).
var cacheWarmupSkipped prometheus.Counter

// cacheWarmupErrors: Compteur total des erreurs lors de la génération/stockage du préchauffage.
var cacheWarmupErrors prometheus.Counter

// cacheWarmupDuration: Histogramme de la durée de préchauffage pour chaque élément individuel.
var cacheWarmupDuration prometheus.Histogram

// cacheWarmupTotalDuration: Jauge de la durée totale du dernier processus de préchauffage.
var cacheWarmupTotalDuration prometheus.Gauge

// pageGenerationDuration: Histogramme (vector) de la durée de génération de page/contenu en cas de cache miss, labellisé par clé de cache.
var pageGenerationDuration *prometheus.HistogramVec

// metricsInitialized assure que l'initialisation des métriques ne se produit qu'une seule fois.
var metricsInitialized atomic.Bool

// setupMonitoring configure les points de terminaison Prometheus et de contrôle de santé.
// Appelé en interne par NewServer.
//
// Args:
//
//	app (*fiber.App): L'instance de l'application Fiber.
//	cfg (Config): La configuration du serveur web.
//	logger (*slog.Logger): Le logger structuré.
//	db (*badger.DB): La connexion à la base de données BadgerDB (L2), utilisée pour le health check (peut être nil).
func setupMonitoring(app *fiber.App, cfg Config, logger *slog.Logger, db *badger.DB) {
	if cfg.EnableMetrics {
		initMetrics(logger)

		fiberProm := fiberprometheus.New("blitzkit_app")
		fiberProm.RegisterAt(app, "/metrics")
		app.Use(fiberProm.Middleware)
		logger.Info("Prometheus metrics enabled", "path", "/metrics")
	}

	app.Get("/health", handleHealthCheck(db, logger))
	logger.Info("Health check endpoint enabled", "path", "/health")
}

// initMetrics initialise les collecteurs Prometheus pour les métriques personnalisées.
// Utilise `atomic.Bool` pour garantir une initialisation unique (thread-safe).
//
// Args:
//
//	logger (*slog.Logger): Le logger pour enregistrer le statut d'initialisation.
func initMetrics(logger *slog.Logger) {
	if metricsInitialized.CompareAndSwap(false, true) {
		logger.Debug("Initializing Prometheus metrics collectors...")
		cacheL1Hits = promauto.NewCounter(prometheus.CounterOpts{Name: "blitzkit_cache_l1_hits_total", Help: "Total L1 cache hits."})
		cacheL1Misses = promauto.NewCounter(prometheus.CounterOpts{Name: "blitzkit_cache_l1_misses_total", Help: "Total L1 cache misses."})
		cacheL1Sets = promauto.NewCounter(prometheus.CounterOpts{Name: "blitzkit_cache_l1_sets_total", Help: "Total items set in L1 cache."})
		cacheL1LoadedFromL2 = promauto.NewCounter(prometheus.CounterOpts{Name: "blitzkit_cache_l1_loaded_from_l2_total", Help: "Total items loaded into L1 from L2."})
		cacheL2Hits = promauto.NewCounter(prometheus.CounterOpts{Name: "blitzkit_cache_l2_hits_total", Help: "Total L2 cache hits."})
		cacheL2Misses = promauto.NewCounter(prometheus.CounterOpts{Name: "blitzkit_cache_l2_misses_total", Help: "Total L2 cache misses (incl. not found, unmarshal errors, db errors)."})
		cacheL2Sets = promauto.NewCounter(prometheus.CounterOpts{Name: "blitzkit_cache_l2_sets_total", Help: "Total items successfully set in L2 cache."})
		cacheL2SetErrors = promauto.NewCounter(prometheus.CounterOpts{Name: "blitzkit_cache_l2_set_errors_total", Help: "Total errors setting items in L2 cache."})
		cacheInvalidations = promauto.NewCounter(prometheus.CounterOpts{Name: "blitzkit_cache_invalidations_total", Help: "Total successful cache invalidations."})
		cacheInvalidationErrors = promauto.NewCounter(prometheus.CounterOpts{Name: "blitzkit_cache_invalidation_errors_total", Help: "Total errors during cache invalidation."})
		cacheWarmupSkipped = promauto.NewCounter(prometheus.CounterOpts{Name: "blitzkit_cache_warmup_skipped_total", Help: "Total items skipped during cache warmup (already in L1)."})
		cacheWarmupErrors = promauto.NewCounter(prometheus.CounterOpts{Name: "blitzkit_cache_warmup_errors_total", Help: "Total errors during cache warmup generation/render/store."})
		cacheWarmupDuration = promauto.NewHistogram(prometheus.HistogramOpts{Name: "blitzkit_cache_warmup_item_duration_seconds", Help: "Duration to warm up individual cache items.", Buckets: prometheus.DefBuckets})
		cacheWarmupTotalDuration = promauto.NewGauge(prometheus.GaugeOpts{Name: "blitzkit_cache_warmup_total_duration_seconds", Help: "Total duration of the last cache warmup process."})
		pageGenerationDuration = promauto.NewHistogramVec(prometheus.HistogramOpts{Name: "blitzkit_page_generation_duration_seconds", Help: "Duration to generate page/byte content (cache miss).", Buckets: prometheus.DefBuckets}, []string{"cache_key"})

		logger.Debug("Prometheus metrics collectors initialized.")
	} else {
		logger.Debug("Prometheus metrics collectors already initialized.")
	}
}

// IncCacheL1Hit incrémente le compteur de succès L1 si les métriques sont initialisées.
func IncCacheL1Hit() {
	if metricsInitialized.Load() {
		cacheL1Hits.Inc()
	}
}

// IncCacheL1Miss incrémente le compteur d'échecs L1 si les métriques sont initialisées.
func IncCacheL1Miss() {
	if metricsInitialized.Load() {
		cacheL1Misses.Inc()
	}
}

// IncCacheL1Set incrémente le compteur d'éléments définis en L1 si les métriques sont initialisées.
func IncCacheL1Set() {
	if metricsInitialized.Load() {
		cacheL1Sets.Inc()
	}
}

// IncCacheL1LoadedFromL2 incrémente le compteur d'éléments L1 chargés depuis L2 si les métriques sont initialisées.
func IncCacheL1LoadedFromL2() {
	if metricsInitialized.Load() {
		cacheL1LoadedFromL2.Inc()
	}
}

// IncCacheL2Hit incrémente le compteur de succès L2 si les métriques sont initialisées.
func IncCacheL2Hit() {
	if metricsInitialized.Load() {
		cacheL2Hits.Inc()
	}
}

// IncCacheL2Miss incrémente le compteur d'échecs L2 si les métriques sont initialisées.
func IncCacheL2Miss() {
	if metricsInitialized.Load() {
		cacheL2Misses.Inc()
	}
}

// IncCacheL2Set incrémente le compteur d'éléments définis en L2 si les métriques sont initialisées.
func IncCacheL2Set() {
	if metricsInitialized.Load() {
		cacheL2Sets.Inc()
	}
}

// IncCacheL2SetErrors incrémente le compteur d'erreurs de définition L2 si les métriques sont initialisées.
func IncCacheL2SetErrors() {
	if metricsInitialized.Load() {
		cacheL2SetErrors.Inc()
	}
}

// IncCacheInvalidations incrémente le compteur d'invalidations réussies si les métriques sont initialisées.
func IncCacheInvalidations() {
	if metricsInitialized.Load() {
		cacheInvalidations.Inc()
	}
}

// IncCacheInvalidationErrors incrémente le compteur d'erreurs d'invalidation si les métriques sont initialisées.
func IncCacheInvalidationErrors() {
	if metricsInitialized.Load() {
		cacheInvalidationErrors.Inc()
	}
}

// IncCacheWarmupSkipped incrémente le compteur d'éléments sautés lors du préchauffage si les métriques sont initialisées.
func IncCacheWarmupSkipped() {
	if metricsInitialized.Load() {
		cacheWarmupSkipped.Inc()
	}
}

// IncCacheWarmupErrors incrémente le compteur d'erreurs de préchauffage si les métriques sont initialisées.
func IncCacheWarmupErrors() {
	if metricsInitialized.Load() {
		cacheWarmupErrors.Inc()
	}
}

// ObserveCacheWarmupDuration enregistre la durée de préchauffage d'un élément individuel si les métriques sont initialisées.
func ObserveCacheWarmupDuration(duration float64) {
	if metricsInitialized.Load() {
		cacheWarmupDuration.Observe(duration)
	}
}

// ObserveCacheWarmupTotalDuration définit la durée totale du dernier préchauffage si les métriques sont initialisées.
func ObserveCacheWarmupTotalDuration(duration float64) {
	if metricsInitialized.Load() {
		cacheWarmupTotalDuration.Set(duration)
	}
}

// ObservePageGenerationDuration enregistre la durée de génération d'une page (cache miss) si les métriques sont initialisées.
func ObservePageGenerationDuration(duration float64, cacheKey string) {
	if metricsInitialized.Load() {
		pageGenerationDuration.WithLabelValues(cacheKey).Observe(duration)
	}
}

// handleHealthCheck retourne un handler Fiber pour le point de terminaison /health.
// Ce handler vérifie le statut des composants critiques (actuellement, le cache L2 BadgerDB via une lecture rapide)
// et retourne une réponse JSON indiquant le statut global ("ok" ou "error") et le statut de chaque composant vérifié.
// Retourne un statut HTTP 200 si tout est OK, ou 503 Service Unavailable si un composant critique est défaillant.
//
// Args:
//
//	db (*badger.DB): La connexion à la base de données BadgerDB (peut être nil si L2 désactivé).
//	logger (*slog.Logger): Le logger structuré.
//
// Returns:
//
//	fiber.Handler: Le handler Fiber pour la route /health.
func handleHealthCheck(db *badger.DB, logger *slog.Logger) fiber.Handler {
	return func(c *fiber.Ctx) error {
		dbStatus := "ok"
		dbErr := ""
		overallStatus := "ok"
		httpStatus := fiber.StatusOK

		if db == nil {
			dbStatus = "unavailable"
			dbErr = "L2 Cache (BadgerDB) is not configured/initialized"
			logger.Warn("Health check: L2 cache DB is nil")
		} else {
			err := db.View(func(txn *badger.Txn) error {
				_, errGet := txn.Get([]byte("health_check_probe"))
				if errGet != nil && !errors.Is(errGet, badger.ErrKeyNotFound) {
					return errGet
				}
				return nil
			})

			if err != nil {
				dbStatus = "unhealthy"
				dbErr = fmt.Sprintf("L2 Cache read check failed: %v", err)
				logger.Error("Health check: L2 Cache read failed", "error", err)
				overallStatus = "error"
				httpStatus = fiber.StatusServiceUnavailable
			} else {
				dbStatus = "ok"
			}
		}

		response := fiber.Map{
			"status":   overallStatus,
			"l2_cache": dbStatus,
		}
		if dbErr != "" {
			response["l2_cache_error"] = dbErr
		}

		return c.Status(httpStatus).JSON(response)
	}
}


# File: package:github.com/r-via/blitzkit/server.go
# ------------------------------------------------------------
// File: server.go
// Description: Définit la structure principale du serveur web (`Server`),
//
//	gère son initialisation, son démarrage, son arrêt propre,
//	et l'enregistrement des éléments pour le préchauffage du cache.
package blitzkit

import (
	"bytes"
	"context"
	"errors"
	"fmt"
	"log/slog"
	"net/http"
	"os"
	"path/filepath"
	"strings"
	"sync"
	"time"

	"github.com/a-h/templ"
	"github.com/dgraph-io/badger/v4"
	"github.com/gofiber/fiber/v2"
	cache "github.com/patrickmn/go-cache"
)

// HeaderCacheStatus est le nom de l'en-tête HTTP utilisé pour indiquer le statut du cache (HIT/MISS).
const HeaderCacheStatus = "X-Cache-Status"

// initOnce garantit que l'initialisation globale (si nécessaire) ne se produit qu'une seule fois.
var initOnce sync.Once

// Server encapsule l'application Fiber, la configuration, le logger, le système de cache,
// et le registre pour le préchauffage du cache.
type Server struct {
	app            *fiber.App
	config         Config
	logger         *slog.Logger
	Cache          *Cache
	warmupRegistry []WarmupRegistration
	warmupMutex    sync.Mutex
}

// Init effectue une initialisation unique pour le package blitzkit.
// Actuellement, ne fait qu'enregistrer un message de débogage.
func Init() {
	initOnce.Do(func() {
		slog.Debug("blitzkit package initialized (initOnce)")
	})
}

// NewServer crée et configure une nouvelle instance du serveur web.
// Valide la configuration fournie, initialise le logger (si non fourni),
// initialise le système de cache (L1/L2), crée l'instance Fiber,
// traite les fichiers statiques (si configuré), met en place les middlewares de base,
// et configure la surveillance (métriques, health check).
//
// Args:
//
//	cfg (Config): La configuration du serveur.
//
// Returns:
//
//	(*Server, error): Une nouvelle instance du serveur et une erreur nil, ou nil et une erreur en cas d'échec de validation ou d'initialisation.
func NewServer(cfg Config) (*Server, error) {
	Init()
	var validationErrors []string

	logger := cfg.Logger
	if logger == nil {
		logLevel := slog.LevelInfo
		if cfg.DevMode {
			logLevel = slog.LevelDebug
		}
		opts := &slog.HandlerOptions{Level: logLevel, AddSource: cfg.DevMode}
		logger = slog.New(slog.NewTextHandler(os.Stderr, opts))
		logger.Info("No logger provided, created default slog logger", "level", logLevel.String(), "dev_mode", cfg.DevMode)
	}
	cfg.Logger = logger

	if cfg.PublicDir != "" {
		abs, err := filepath.Abs(cfg.PublicDir)
		if err != nil {
			validationErrors = append(validationErrors, fmt.Sprintf("PublicDir '%s' invalid path: %v", cfg.PublicDir, err))
		} else {
			cfg.PublicDir = abs
		}
		if err := ensureDirExists(cfg.PublicDir, logger); err != nil {
			validationErrors = append(validationErrors, fmt.Sprintf("PublicDir creation failed: %v", err))
		}
	} else {
		logger.Warn("PublicDir is not configured. Serving static files via app.Static('/') will likely fail or use default.")
	}
	if cfg.CacheDir != "" {
		abs, err := filepath.Abs(cfg.CacheDir)
		if err != nil {
			validationErrors = append(validationErrors, fmt.Sprintf("CacheDir '%s' invalid path: %v", cfg.CacheDir, err))
		} else {
			cfg.CacheDir = abs
		}
		if err := ensureDirExists(cfg.CacheDir, logger); err != nil {
			validationErrors = append(validationErrors, fmt.Sprintf("CacheDir creation failed: %v", err))
		}
		if err := checkDirWritable(cfg.CacheDir, logger); err != nil {
			validationErrors = append(validationErrors, fmt.Sprintf("CacheDir '%s' not writable: %v", cfg.CacheDir, err))
		}
	}
	if cfg.SourcesDir != "" {
		if err := ensureDirExists(cfg.SourcesDir, logger); err != nil {
			validationErrors = append(validationErrors, fmt.Sprintf("SourcesDir check/creation failed: %v", err))
		}
	}
	if cfg.StaticsDir != "" {
		if err := ensureDirExists(cfg.StaticsDir, logger); err != nil {
			validationErrors = append(validationErrors, fmt.Sprintf("StaticsDir check/creation failed: %v", err))
		}
	}

	cfg.Port = getEnvOrDefault(logger, "PORT", cfg.Port, "8080")
	cfg.ReadTimeout = defaultDuration(cfg.ReadTimeout, 30*time.Second)
	cfg.WriteTimeout = defaultDuration(cfg.WriteTimeout, 30*time.Second)
	cfg.IdleTimeout = defaultDuration(cfg.IdleTimeout, 60*time.Second)
	cfg.WarmupConcurrency = defaultInt(cfg.WarmupConcurrency, 4)
	cfg.CacheL1DefaultTTL = parseDurationEnv("CACHE_L1_DEFAULT_TTL", cfg.CacheL1DefaultTTL, 5*time.Minute, logger)
	cfg.CacheL2DefaultTTL = parseDurationEnv("CACHE_L2_DEFAULT_TTL", cfg.CacheL2DefaultTTL, 24*time.Hour, logger)
	cfg.BadgerGCInterval = parseDurationEnv("BADGER_GC_INTERVAL", cfg.BadgerGCInterval, 1*time.Hour, logger)
	if cfg.BadgerGCDiscardRatio <= 0 || cfg.BadgerGCDiscardRatio >= 1.0 {
		if cfg.BadgerGCDiscardRatio != 0 {
			logger.Warn("Invalid BadgerGCDiscardRatio, using 0.5", "value", cfg.BadgerGCDiscardRatio)
		}
		cfg.BadgerGCDiscardRatio = 0.5
	}

	logger.Info("Effective blitzkit Core Config",
		slog.String("Port", cfg.Port), slog.Duration("ReadTimeout", cfg.ReadTimeout), slog.Duration("WriteTimeout", cfg.WriteTimeout),
		slog.Duration("IdleTimeout", cfg.IdleTimeout), slog.Bool("DevMode", cfg.DevMode),
		slog.String("PublicDir", cfg.PublicDir), slog.String("CacheDir", cfg.CacheDir), slog.String("SourcesDir", cfg.SourcesDir), slog.String("StaticsDir", cfg.StaticsDir),
		slog.Duration("CacheL1TTL", cfg.CacheL1DefaultTTL), slog.Duration("CacheL2TTL", cfg.CacheL2DefaultTTL),
		slog.Duration("BadgerGCInterval", cfg.BadgerGCInterval), slog.Float64("BadgerGCDiscardRatio", cfg.BadgerGCDiscardRatio),
		slog.Bool("EnableMetrics", cfg.EnableMetrics), slog.Int("WarmupConcurrency", cfg.WarmupConcurrency),
	)

	var cacheSystem *Cache
	var cacheErr error
	if cfg.CacheDir != "" {
		cacheL1CleanupInterval := parseDurationEnv("CACHE_L1_CLEANUP_INTERVAL", 0, 10*time.Minute, logger)
		cacheSystem, cacheErr = NewCache(cfg.CacheDir, logger, cacheL1CleanupInterval, cfg.BadgerGCInterval, cfg.BadgerGCDiscardRatio)
		if cacheErr != nil {
			validationErrors = append(validationErrors, fmt.Sprintf("Cache init failed: %v", cacheErr))
		}
	} else {
		logger.Warn("CacheDir not configured. L2 cache disabled. Using only L1 cache.")
		cacheL1CleanupInterval := parseDurationEnv("CACHE_L1_CLEANUP_INTERVAL", 0, 10*time.Minute, logger)
		l1 := cache.New(cache.NoExpiration, cacheL1CleanupInterval)
		cacheSystem = &Cache{L1: l1, L2: nil}
	}
	if cacheSystem == nil && cacheErr == nil {
		validationErrors = append(validationErrors, "Cache system initialization returned nil unexpectedly")
	}

	if len(validationErrors) > 0 {
		err := fmt.Errorf("blitzkit config validation failed: %s", strings.Join(validationErrors, "; "))
		logger.Error("Configuration validation failed", "errors", validationErrors)
		if cacheSystem != nil {
			_ = cacheSystem.Close(logger)
		}
		return nil, err
	}
	logger.Debug("Configuration validation passed.")

	s := &Server{
		config:         cfg,
		logger:         logger,
		Cache:          cacheSystem,
		warmupRegistry: make([]WarmupRegistration, 0),
	}

	errorHandler := s.handleError
	if cfg.ErrorHandler != nil {
		errorHandler = cfg.ErrorHandler
	}
	fiberConfig := fiber.Config{
		ReadTimeout:           cfg.ReadTimeout,
		WriteTimeout:          cfg.WriteTimeout,
		IdleTimeout:           cfg.IdleTimeout,
		ErrorHandler:          errorHandler,
		DisableStartupMessage: true,
		AppName:               "GoReviewApp v1.1",
		Prefork:               !cfg.DevMode,
	}
	app := fiber.New(fiberConfig)
	s.app = app

	if cfg.PublicDir != "" && (cfg.SourcesDir != "" || cfg.StaticsDir != "") {
		processor := NewStaticProcessor(cfg.SourcesDir, cfg.StaticsDir, cfg.PublicDir, logger, cfg.DevMode)
		if err := processor.Process(); err != nil {
			logger.Error("Failed to process static files on startup, check permissions and paths", "error", err)
		}
	} else {
		logger.Info("Static file processing skipped (required directories not configured or PublicDir invalid).")
	}

	s.setupBaseMiddlewares()

	var l2db *badger.DB = nil
	if s.Cache != nil {
		l2db = s.Cache.L2
	}
	setupMonitoring(app, cfg, logger, l2db)

	logger.Info("blitzkit instance created. Register warmup items via handlers/init.")
	return s, nil
}

// App retourne l'instance sous-jacente de l'application Fiber.
// Panic si l'instance Fiber n'a pas été initialisée.
//
// Returns:
//
//	*fiber.App: L'instance de l'application Fiber.
func (s *Server) App() *fiber.App {
	if s.app == nil {
		panic("Server.App() called on a nil Fiber instance")
	}
	return s.app
}

// GetLogger retourne l'instance du logger slog configurée pour ce serveur.
//
// Returns:
//
//	*slog.Logger: Le logger configuré.
func (s *Server) GetLogger() *slog.Logger {
	return s.logger
}

// GetConfig retourne une copie de la configuration effective du serveur.
//
// Returns:
//
//	Config: La configuration actuelle du serveur.
func (s *Server) GetConfig() Config {
	return s.config
}

// Start démarre le serveur web Fiber et le fait écouter sur le port configuré.
// Bloque jusqu'à ce que le serveur soit arrêté (par Shutdown ou une erreur fatale).
// Gère l'affichage des messages de démarrage en fonction du mode (Dev/Prod, Master/Child).
//
// Returns:
//
//	error: Une erreur si l'écoute échoue (autre que `http.ErrServerClosed`), sinon nil après un arrêt propre.
func (s *Server) Start() error {
	port := s.config.Port
	if port == "" {
		port = "8080"
	}
	addr := fmt.Sprintf(":%s", port)
	preforkStatus := "disabled"
	if !s.config.DevMode && fiber.IsChild() {
		preforkStatus = "enabled (child)"
	} else if !s.config.DevMode {
		preforkStatus = "enabled (master)"
	}

	if !s.config.DevMode && fiber.IsChild() {
	} else {
		s.logger.Info("Server starting listener...", "address", addr, "dev_mode", s.config.DevMode, "prefork", preforkStatus)
	}

	if err := s.app.Listen(addr); err != nil {
		if !errors.Is(err, http.ErrServerClosed) {
			s.logger.Error("Server failed to start or stopped unexpectedly", "address", addr, "error", err)
			return fmt.Errorf("server listen failed on %s: %w", addr, err)
		}
		if !(!s.config.DevMode && fiber.IsChild()) {
			s.logger.Info("Server stopped listening gracefully", "address", addr)
		}
	}
	return nil
}

// Shutdown tente d'arrêter proprement le serveur web et de fermer le système de cache.
// Utilise `ShutdownWithTimeout` pour l'application Fiber et appelle `Cache.Close()`.
// Logue le processus et retourne la première erreur rencontrée.
// Gère le cas des processus enfants en mode prefork (qui n'exécutent pas l'arrêt complet).
//
// Returns:
//
//	error: La première erreur rencontrée lors de l'arrêt de Fiber ou du cache, ou nil si tout s'est bien passé.
func (s *Server) Shutdown() error {
	if !s.config.DevMode && fiber.IsChild() {
		s.logger.Debug("Prefork child process shutting down", "pid", os.Getpid())
		return nil
	}

	s.logger.Info("Initiating graceful shutdown...")
	shutdownTimeout := 30 * time.Second
	var wg sync.WaitGroup
	var firstErr error
	errChan := make(chan error, 2)

	wg.Add(1)
	go func() {
		defer wg.Done()
		s.logger.Debug("Shutting down Fiber application...")
		if s.app != nil {
			if err := s.app.ShutdownWithTimeout(shutdownTimeout); err != nil {
				if !errors.Is(err, context.DeadlineExceeded) && !errors.Is(err, http.ErrServerClosed) {
					s.logger.Error("Fiber shutdown error", "error", err)
					errChan <- fmt.Errorf("fiber shutdown failed: %w", err)
				} else if errors.Is(err, context.DeadlineExceeded) {
					s.logger.Warn("Fiber shutdown timed out waiting for connections to close", "timeout", shutdownTimeout)
				} else {
					s.logger.Debug("Fiber shutdown completed (ErrServerClosed received).")
				}
			} else {
				s.logger.Debug("Fiber shutdown completed successfully.")
			}
		} else {
			s.logger.Warn("Fiber app was nil during shutdown.")
		}
	}()

	if s.Cache != nil {
		wg.Add(1)
		go func() {
			defer wg.Done()
			s.logger.Debug("Closing cache system...")
			if err := s.Cache.Close(s.logger); err != nil {
				s.logger.Error("Cache system close error", "error", err)
				errChan <- fmt.Errorf("cache system close failed: %w", err)
			} else {
				s.logger.Debug("Cache system closed successfully.")
			}
		}()
	} else {
		s.logger.Debug("Cache system is nil, skipping close.")
	}

	wg.Wait()
	close(errChan)

	for err := range errChan {
		if firstErr == nil {
			firstErr = err
		} else {
			s.logger.Error("Additional shutdown error occurred", "subsequent_error", err)
		}
	}

	if firstErr == nil {
		s.logger.Info("Server shutdown procedures completed successfully.")
	} else {
		s.logger.Error("Server shutdown procedures completed with errors.", "first_error", firstErr)
	}
	return firstErr
}

// RegisterForPageWarmup enregistre une fonction de génération de page HTML (Templ)
// pour le processus de préchauffage du cache.
// Le générateur doit retourner un `templ.Component` et un timestamp `lastModified`.
//
// Args:
//
//	key (string): La clé de cache unique pour cette page.
//	ttlInfo (CacheTTLInfo): Les informations sur la durée de vie du cache.
//	generator (PageGeneratorFunc): La fonction qui génère le contenu de la page.
func (s *Server) RegisterForPageWarmup(key string, ttlInfo CacheTTLInfo, generator PageGeneratorFunc) {
	s.warmupMutex.Lock()
	defer s.warmupMutex.Unlock()
	if generator == nil {
		s.logger.Warn("Skipping page warmup registration: generator is nil", "key", key)
		return
	}
	s.logger.Debug("Registering page for warmup", "key", key)
	s.warmupRegistry = append(s.warmupRegistry, WarmupRegistration{
		Key:           key,
		GeneratorFunc: generator,
		IsBytes:       false,
		TTLInfo:       ttlInfo,
	})
}

// RegisterForBytesWarmup enregistre une fonction de génération de données binaires
// pour le processus de préchauffage du cache.
// Le générateur doit retourner une slice de bytes (`[]byte`) et un timestamp `lastModified`.
//
// Args:
//
//	key (string): La clé de cache unique pour ces données.
//	ttlInfo (CacheTTLInfo): Les informations sur la durée de vie du cache.
//	generator (BytesGeneratorFunc): La fonction qui génère les données binaires.
func (s *Server) RegisterForBytesWarmup(key string, ttlInfo CacheTTLInfo, generator BytesGeneratorFunc) {
	s.warmupMutex.Lock()
	defer s.warmupMutex.Unlock()
	if generator == nil {
		s.logger.Warn("Skipping bytes warmup registration: generator is nil", "key", key)
		return
	}
	s.logger.Debug("Registering bytes for warmup", "key", key)
	s.warmupRegistry = append(s.warmupRegistry, WarmupRegistration{
		Key:           key,
		GeneratorFunc: generator,
		IsBytes:       true,
		TTLInfo:       ttlInfo,
	})
}

// ExecuteWarmup exécute le processus de préchauffage du cache pour tous les éléments enregistrés.
// Il génère le contenu pour chaque clé enregistrée (si elle n'est pas déjà dans L1) en utilisant
// la fonction de génération fournie, puis stocke le résultat dans les caches L1 et L2.
// Utilise des goroutines et un sémaphore pour contrôler la concurrence selon `WarmupConcurrency`.
// Logue le processus et retourne une erreur agrégée si des erreurs surviennent.
//
// Returns:
//
//	error: Une erreur agrégée contenant les erreurs de tous les éléments qui ont échoué, ou nil si tout réussit.
func (s *Server) ExecuteWarmup() error {
	s.warmupMutex.Lock()
	itemsToWarmup := make([]WarmupRegistration, len(s.warmupRegistry))
	copy(itemsToWarmup, s.warmupRegistry)
	s.warmupMutex.Unlock()

	if len(itemsToWarmup) == 0 {
		s.logger.Info("No items registered for cache warmup.")
		return nil
	}
	if s.Cache == nil {
		s.logger.Error("Cannot perform warmup: Cache system is not initialized.")
		return fmt.Errorf("cache system not initialized, cannot perform warmup")
	}

	maxConcurrent := s.config.WarmupConcurrency
	if maxConcurrent <= 0 {
		maxConcurrent = 1
	}
	s.logger.Info("Starting registered cache warm-up...", "count", len(itemsToWarmup), "concurrency", maxConcurrent)

	var wg sync.WaitGroup
	sem := make(chan struct{}, maxConcurrent)
	errChan := make(chan error, len(itemsToWarmup))
	start := time.Now()

	for i, itemReg := range itemsToWarmup {
		currentIndex := i
		currentItem := itemReg

		wg.Add(1)
		sem <- struct{}{}
		go func() {
			defer wg.Done()
			defer func() { <-sem }()
			logCtx := s.logger.With("cache_key", currentItem.Key, "item_index", currentIndex+1)
			itemStart := time.Now()

			if s.Cache.L1 != nil {
				if _, found := s.Cache.L1.Get(currentItem.Key); found {
					logCtx.Debug("[Warmup] Skipped: Already in L1")
					IncCacheWarmupSkipped()
					ObserveCacheWarmupDuration(time.Since(itemStart).Seconds())
					return
				}
			}

			var generatedBytes []byte
			var lastModified int64 = time.Now().Unix()
			var genErr error

			logCtx.Debug("[Warmup] Generating content")
			if currentItem.IsBytes {
				if generator, ok := currentItem.GeneratorFunc.(BytesGeneratorFunc); ok && generator != nil {
					generatedBytes, lastModified, genErr = generator()
				} else {
					genErr = fmt.Errorf("invalid or nil generator type for bytes warmup")
				}
			} else {
				if generator, ok := currentItem.GeneratorFunc.(PageGeneratorFunc); ok && generator != nil {
					var component templ.Component
					component, lastModified, genErr = generator()
					if genErr == nil && component != nil {
						var buf bytes.Buffer
						renderErr := component.Render(context.Background(), &buf)
						if renderErr != nil {
							genErr = fmt.Errorf("render failed: %w", renderErr)
						} else {
							generatedBytes = buf.Bytes()
						}
					} else if genErr == nil {
						genErr = errors.New("generator returned nil component")
					}
				} else {
					genErr = fmt.Errorf("invalid or nil generator type for page warmup")
				}
			}

			if genErr != nil {
				logCtx.Error("[Warmup] Generator/Render failed", "error", genErr)
				errChan <- fmt.Errorf("key %s: %w", currentItem.Key, genErr)
				IncCacheWarmupErrors()
				return
			}
			if generatedBytes == nil {
				logCtx.Error("[Warmup] Generator produced nil bytes")
				errChan <- fmt.Errorf("key %s: generator produced nil bytes", currentItem.Key)
				IncCacheWarmupErrors()
				return
			}

			l2StoreErr := s.storeInL2(currentItem.Key, CacheEntry{Data: generatedBytes, LastModified: lastModified}, currentItem.TTLInfo.IsInfinite)
			if l2StoreErr != nil {
				logCtx.Warn("[Warmup] Failed to store in L2, proceeding with L1 if available", "error", l2StoreErr)
			} else {
				logCtx.Debug("[Warmup] Stored in L2 successfully")
			}

			if s.Cache.L1 != nil {
				l1TTL := s.config.CacheL1DefaultTTL
				if currentItem.TTLInfo.IsInfinite {
					l1TTL = cache.NoExpiration
				}
				s.Cache.L1.Set(currentItem.Key, generatedBytes, l1TTL)
				IncCacheL1Set()
				logCtx.Debug("[Warmup] Stored in L1 successfully", "l1_ttl", l1TTL)
			}

			logCtx.Debug("[Warmup] Item processed successfully", "duration", time.Since(itemStart))
			ObserveCacheWarmupDuration(time.Since(itemStart).Seconds())
		}()
	}

	wg.Wait()
	close(errChan)
	totalDuration := time.Since(start)
	ObserveCacheWarmupTotalDuration(totalDuration.Seconds())

	var warmupErrs []string
	errorCount := 0
	for err := range errChan {
		warmupErrs = append(warmupErrs, err.Error())
		errorCount++
	}
	if errorCount > 0 {
		fullError := fmt.Errorf("%d errors during cache warm-up: %s", errorCount, strings.Join(warmupErrs, "; "))
		s.logger.Error("Registered cache warm-up completed with errors", "details", fullError.Error())
		return fullError
	}
	s.logger.Info("Registered cache warm-up finished.", "duration", totalDuration)
	return nil
}


# File: package:github.com/r-via/blitzkit/sitemap.go
# ------------------------------------------------------------
// File: sitemap.go
// Description: Fournit les structures et fonctions nécessaires pour générer
//
//	un fichier sitemap.xml conforme au protocole sitemap standard.
package blitzkit

import (
	"bytes"
	"encoding/xml"
	"fmt"
	"time"
)

// SitemapEntry représente une entrée URL unique dans un sitemap XML.
// Contient l'URL (loc), la date de dernière modification (lastmod),
// la fréquence de changement (changefreq), et la priorité.
type SitemapEntry struct {
	XMLName    xml.Name   `xml:"url"`
	URL        string     `xml:"loc"`
	LastMod    *time.Time `xml:"lastmod,omitempty"`
	ChangeFreq string     `xml:"changefreq,omitempty"`
	Priority   float32    `xml:"priority,omitempty"`
}

// SitemapChangeFreqAlways indique que le contenu change à chaque accès.
const SitemapChangeFreqAlways = "always"

// SitemapChangeFreqHourly indique que le contenu change environ toutes les heures.
const SitemapChangeFreqHourly = "hourly"

// SitemapChangeFreqDaily indique que le contenu change environ tous les jours.
const SitemapChangeFreqDaily = "daily"

// SitemapChangeFreqWeekly indique que le contenu change environ toutes les semaines.
const SitemapChangeFreqWeekly = "weekly"

// SitemapChangeFreqMonthly indique que le contenu change environ tous les mois.
const SitemapChangeFreqMonthly = "monthly"

// SitemapChangeFreqYearly indique que le contenu change environ tous les ans.
const SitemapChangeFreqYearly = "yearly"

// SitemapChangeFreqNever indique que le contenu est archivé et ne change jamais.
const SitemapChangeFreqNever = "never"

// urlset est l'élément racine du document sitemap XML.
// Il contient l'attribut de namespace requis et une liste d'éléments <url>.
type urlset struct {
	XMLName xml.Name       `xml:"urlset"`
	Xmlns   string         `xml:"xmlns,attr"`
	URLs    []SitemapEntry `xml:"url"`
}

// GenerateSitemapXMLBytes génère le contenu complet d'un fichier sitemap.xml
// sous forme de slice de bytes, à partir d'une liste d'entrées SitemapEntry.
// Inclut l'en-tête XML et l'élément racine <urlset> avec le namespace correct.
//
// Args:
//
//	entries ([]SitemapEntry): La liste des entrées URL à inclure dans le sitemap.
//
// Returns:
//
//	([]byte, error): La slice de bytes contenant le XML généré, ou nil et une erreur si l'encodage échoue.
func GenerateSitemapXMLBytes(entries []SitemapEntry) ([]byte, error) {
	if entries == nil {
		entries = []SitemapEntry{}
	}

	sitemap := urlset{
		Xmlns: "http://www.sitemaps.org/schemas/sitemap/0.9",
		URLs:  entries,
	}

	var buf bytes.Buffer
	buf.WriteString(xml.Header)

	encoder := xml.NewEncoder(&buf)
	encoder.Indent("", "  ")

	if err := encoder.Encode(sitemap); err != nil {
		return nil, fmt.Errorf("failed to encode sitemap XML: %w", err)
	}

	return buf.Bytes(), nil
}


# File: package:github.com/r-via/blitzkit/static_processor.go
# ------------------------------------------------------------
// File: static_processor.go
// Description: Gère le traitement des fichiers statiques (CSS, JS) au démarrage du serveur.
//
//	Inclut la minification des fichiers sources et la copie des fichiers statiques
//	vers le répertoire public.
package blitzkit

import (
	"errors"
	"fmt"
	"io"
	"io/fs"
	"log/slog"
	"os"
	"path/filepath"
	"strings"

	"github.com/tdewolff/minify/v2"
	"github.com/tdewolff/minify/v2/css"
	"github.com/tdewolff/minify/v2/js"
)

// StaticProcessor gère la minification et la copie des ressources statiques.
// Il lit depuis `sourcesDir` (pour minifier CSS/JS) et `staticsDir` (pour copier),
// et écrit le résultat dans `publicDir`.
type StaticProcessor struct {
	sourcesDir string
	staticsDir string
	publicDir  string
	logger     *slog.Logger
	minifier   *minify.M
	devMode    bool
}

// NewStaticProcessor crée une nouvelle instance de StaticProcessor.
// Initialise le minificateur pour CSS et JS.
//
// Args:
//
//	sourcesDir (string): Répertoire contenant les fichiers CSS/JS à minifier.
//	staticsDir (string): Répertoire contenant les fichiers statiques à copier tels quels.
//	publicDir (string): Répertoire de destination où les fichiers traités seront écrits.
//	logger (*slog.Logger): Le logger structuré.
//	devMode (bool): Indicateur du mode développement (peut affecter la minification ou la sélection de fichiers).
//
// Returns:
//
//	*StaticProcessor: Une nouvelle instance de StaticProcessor.
func NewStaticProcessor(sourcesDir, staticsDir, publicDir string, logger *slog.Logger, devMode bool) *StaticProcessor {
	if logger == nil {
		logger = slog.Default()
		logger.Warn("StaticProcessor using default logger.")
	}
	m := minify.New()
	m.AddFunc("text/css", css.Minify)
	m.AddFunc("application/javascript", js.Minify)

	return &StaticProcessor{
		sourcesDir: sourcesDir,
		staticsDir: staticsDir,
		publicDir:  publicDir,
		logger:     logger,
		minifier:   m,
		devMode:    devMode,
	}
}

// Process exécute le pipeline complet de traitement des ressources statiques :
// 1. Purge (supprime et recrée) le répertoire public de destination.
// 2. Minifie les fichiers CSS et JS trouvés dans le répertoire source.
// 3. Copie tous les fichiers et répertoires du répertoire statique.
// Retourne une erreur agrégée si des étapes échouent.
//
// Returns:
//
//	error: Une erreur si la purge, la minification ou la copie échoue, sinon nil.
func (sp *StaticProcessor) Process() error {
	logCtx := sp.logger.With(
		slog.String("sources_dir", sp.sourcesDir),
		slog.String("statics_dir", sp.staticsDir),
		slog.String("public_dir", sp.publicDir),
		slog.Bool("dev_mode", sp.devMode),
	)
	logCtx.Info("Processing static assets...")

	if sp.publicDir != "" {
		if err := sp.purgePublicDir(); err != nil {
			logCtx.Error("Failed to purge public directory, processing might overwrite files", "error", err)
		}
	} else {
		logCtx.Error("PublicDir is not configured, cannot process static assets.")
		return errors.New("PublicDir is required for StaticProcessor")
	}

	var processErrors []string

	if sp.sourcesDir != "" {
		if err := sp.minifyFiles(); err != nil {
			logCtx.Error("Error during source file minification", "error", err)
			processErrors = append(processErrors, fmt.Sprintf("minify failed: %v", err))
		}
	} else {
		logCtx.Info("SourcesDir not configured, skipping minification.")
	}

	if sp.staticsDir != "" {
		if err := sp.copyFiles(); err != nil {
			logCtx.Error("Error during static file copying", "error", err)
			processErrors = append(processErrors, fmt.Sprintf("copy failed: %v", err))
		}
	} else {
		logCtx.Info("StaticsDir not configured, skipping static file copy.")
	}

	if len(processErrors) > 0 {
		logCtx.Warn("Static asset processing completed with errors.", "errors", processErrors)
		return fmt.Errorf("static processing errors: %s", strings.Join(processErrors, "; "))
	}

	logCtx.Info("Static asset processing completed successfully.")
	return nil
}

// purgePublicDir supprime le contenu existant du répertoire public et le recrée.
// Contient des sécurités pour éviter de supprimer des chemins invalides (ex: "/", ".").
//
// Returns:
//
//	error: Une erreur si le chemin est invalide, si la suppression ou la recréation échoue.
func (sp *StaticProcessor) purgePublicDir() error {
	logCtx := sp.logger.With(slog.String("public_dir", sp.publicDir))
	logCtx.Debug("Purging public directory...")

	if sp.publicDir == "" || sp.publicDir == "/" || sp.publicDir == "." {
		logCtx.Error("Refusing to purge invalid public directory path")
		return errors.New("invalid public directory path for purging")
	}

	if _, err := os.Stat(sp.publicDir); err == nil {
		errRemove := os.RemoveAll(sp.publicDir)
		if errRemove != nil {
			logCtx.Error("Failed to remove existing public directory", "error", errRemove)
			return fmt.Errorf("failed to remove %s: %w", sp.publicDir, errRemove)
		}
	} else if !errors.Is(err, fs.ErrNotExist) {
		logCtx.Error("Failed to stat public directory before purge", "error", err)
		return fmt.Errorf("failed to stat %s before purge: %w", sp.publicDir, err)
	}

	if err := os.MkdirAll(sp.publicDir, 0755); err != nil {
		logCtx.Error("Failed to recreate public directory", "error", err)
		return fmt.Errorf("failed to create %s: %w", sp.publicDir, err)
	}

	logCtx.Debug("Public directory purged and recreated.")
	return nil
}

// minifyFiles parcourt le répertoire `sourcesDir`, identifie les fichiers CSS et JS
// (en gérant la priorité des fichiers `.debug.js` en mode dev), les minifie
// (sauf si désactivé pour JS en mode dev), et écrit le résultat dans le `publicDir`
// en conservant la structure de sous-répertoires relative.
//
// Returns:
//
//	error: Une erreur si le parcours du répertoire ou une opération de fichier/minification échoue.
func (sp *StaticProcessor) minifyFiles() error {
	logCtx := sp.logger.With(slog.String("sources_dir", sp.sourcesDir), slog.String("public_dir", sp.publicDir))
	logCtx.Info("Minifying source assets (CSS/JS)...")

	dirInfo, err := os.Stat(sp.sourcesDir)
	if os.IsNotExist(err) {
		logCtx.Info("Source directory does not exist, skipping minification.")
		return nil
	}
	if err != nil {
		return fmt.Errorf("failed stat %s: %w", sp.sourcesDir, err)
	}
	if !dirInfo.IsDir() {
		return fmt.Errorf("%s is not a directory", sp.sourcesDir)
	}

	filesProcessed := 0
	filesToProcess := make(map[string]string)

	err = filepath.WalkDir(sp.sourcesDir, func(srcPath string, d fs.DirEntry, walkErr error) error {
		if walkErr != nil {
			logCtx.Error("Walk error", "path", srcPath, "error", walkErr)
			return walkErr
		}
		if d.IsDir() {
			return nil
		}

		fileName := d.Name()
		isCSS := strings.HasSuffix(fileName, ".css")
		isDebugJS := strings.HasSuffix(fileName, ".debug.js")
		isStandardJS := strings.HasSuffix(fileName, ".js") && !isDebugJS

		if !isCSS && !isDebugJS && !isStandardJS {
			return nil
		}

		baseFileName := fileName
		if isDebugJS {
			baseFileName = strings.TrimSuffix(fileName, ".debug.js") + ".js"
		}

		relSrcPath, errRel := filepath.Rel(sp.sourcesDir, srcPath)
		if errRel != nil {
			logCtx.Error("Failed get relative path", "file", srcPath, "error", errRel)
			return nil
		}

		destRelPath := filepath.ToSlash(filepath.Join(filepath.Dir(relSrcPath), baseFileName))
		destPath := filepath.Join(sp.publicDir, destRelPath)

		currentSrc, exists := filesToProcess[destPath]
		shouldReplace := !exists
		if exists {
			currentIsDebug := strings.HasSuffix(currentSrc, ".debug.js")
			newIsDebug := isDebugJS
			if sp.devMode && newIsDebug && !currentIsDebug {
				shouldReplace = true
			}
			if !sp.devMode && !newIsDebug && currentIsDebug {
				shouldReplace = true
			}
		}

		if shouldReplace {
			if sp.devMode && exists {
				logCtx.Debug("Replacing file candidate for DevMode", "destination", destPath, "old_source", currentSrc, "new_source", srcPath)
			}
			if !sp.devMode && exists {
				logCtx.Debug("Replacing file candidate for ProdMode", "destination", destPath, "old_source", currentSrc, "new_source", srcPath)
			}
			filesToProcess[destPath] = srcPath
		}
		return nil
	})
	if err != nil {
		return fmt.Errorf("failed scanning %s for minification: %w", sp.sourcesDir, err)
	}

	logCtx.Debug("Processing selected files for minification", "count", len(filesToProcess))
	for destPath, srcPath := range filesToProcess {
		fileLogCtx := logCtx.With(slog.String("source", srcPath), slog.String("destination", destPath))
		if sp.devMode {
			fileLogCtx.Debug("Processing file")
		}

		destSubDir := filepath.Dir(destPath)
		if err := os.MkdirAll(destSubDir, 0755); err != nil {
			fileLogCtx.Error("Failed create destination subdir", "path", destSubDir, "error", err)
			continue
		}

		srcContent, errRead := os.ReadFile(srcPath)
		if errRead != nil {
			fileLogCtx.Error("Failed read source file", "error", errRead)
			continue
		}

		var mediaType string
		if strings.HasSuffix(srcPath, ".css") {
			mediaType = "text/css"
		} else {
			mediaType = "application/javascript"
		}

		minifiedContent, minifyErr := sp.minifier.Bytes(mediaType, srcContent)
		if minifyErr != nil {
			fileLogCtx.Error("Minification failed, using original content", "error", minifyErr)
			minifiedContent = srcContent
		}

		if errWrite := os.WriteFile(destPath, minifiedContent, 0644); errWrite != nil {
			fileLogCtx.Error("Failed write destination file", "error", errWrite)
			continue
		}
		filesProcessed++
	}

	logCtx.Info("Source asset minification completed", "files_processed", filesProcessed)
	return nil
}

// copyFiles parcourt le répertoire `staticsDir` et copie récursivement tous
// les fichiers et sous-répertoires vers le `publicDir`, en préservant la structure.
//
// Returns:
//
//	error: Une erreur si le parcours ou une opération de copie/création de répertoire échoue.
func (sp *StaticProcessor) copyFiles() error {
	logCtx := sp.logger.With(slog.String("statics_dir", sp.staticsDir), slog.String("public_dir", sp.publicDir))
	logCtx.Info("Copying static assets...")

	dirInfo, err := os.Stat(sp.staticsDir)
	if os.IsNotExist(err) {
		logCtx.Info("Statics directory does not exist, skipping copy.")
		return nil
	}
	if err != nil {
		return fmt.Errorf("failed stat %s: %w", sp.staticsDir, err)
	}
	if !dirInfo.IsDir() {
		return fmt.Errorf("%s is not a directory", sp.staticsDir)
	}

	filesCopiedCount := 0
	dirsCreatedCount := 0

	err = filepath.WalkDir(sp.staticsDir, func(srcPath string, d fs.DirEntry, walkErr error) error {
		if walkErr != nil {
			logCtx.Error("Walk error during copy", "path", srcPath, "error", walkErr)
			return walkErr
		}
		if srcPath == sp.staticsDir {
			return nil
		}

		relPath, errRel := filepath.Rel(sp.staticsDir, srcPath)
		if errRel != nil {
			logCtx.Error("Failed get relative path during copy", "path", srcPath, "error", errRel)
			return nil
		}

		destPath := filepath.Join(sp.publicDir, relPath)

		if d.IsDir() {
			if errMkdir := os.MkdirAll(destPath, 0755); errMkdir != nil {
				logCtx.Error("Failed create destination directory during copy", "path", destPath, "error", errMkdir)
				return errMkdir
			}
			dirsCreatedCount++
			if sp.devMode {
				logCtx.Debug("Created directory", "destination", destPath)
			}
			return nil
		} else {
			errCopy := copyFile(srcPath, destPath)
			if errCopy != nil {
				logCtx.Error("Failed to copy file", "source", srcPath, "destination", destPath, "error", errCopy)
				return nil
			}
			filesCopiedCount++
			if sp.devMode {
				logCtx.Debug("Copied file", "source", srcPath, "destination", destPath)
			}
			return nil
		}
	})

	if err != nil {
		return fmt.Errorf("failed during walk for copy from %s: %w", sp.staticsDir, err)
	}
	logCtx.Info("Static file copy process completed", "files_copied", filesCopiedCount, "directories_created", dirsCreatedCount)
	return nil
}

// copyFile copie le contenu d'un fichier source vers un fichier destination.
// Crée ou écrase le fichier destination.
//
// Args:
//
//	src (string): Chemin du fichier source.
//	dst (string): Chemin du fichier destination.
//
// Returns:
//
//	error: Une erreur si l'ouverture, la création ou la copie échoue.
func copyFile(src, dst string) error {
	srcFile, err := os.Open(src)
	if err != nil {
		return fmt.Errorf("open source %s: %w", src, err)
	}
	defer srcFile.Close()

	dstFile, err := os.Create(dst)
	if err != nil {
		return fmt.Errorf("create destination %s: %w", dst, err)
	}
	defer dstFile.Close()

	_, err = io.Copy(dstFile, srcFile)
	if err != nil {
		return fmt.Errorf("copy %s to %s: %w", src, dst, err)
	}

	return nil
}


# File: package:github.com/r-via/blitzkit/types.go
# ------------------------------------------------------------
// File: types.go
// Description: Définit les types de données et interfaces utilisés par le package blitzkit,
//
//	y compris la structure de configuration `Config`, les types de fonctions
//	pour les générateurs de cache, et les types liés au préchauffage du cache.
package blitzkit

import (
	"log/slog"
	"time"

	"github.com/a-h/templ"
	"github.com/gofiber/fiber/v2"
)

// Config regroupe tous les paramètres de configuration du serveur web.
type Config struct {
	// Port: Le port TCP sur lequel le serveur écoute (ex: "8080").
	Port string `json:"port" yaml:"port"`
	// ReadTimeout: Durée maximale pour lire l'intégralité de la requête, y compris le corps.
	ReadTimeout time.Duration `json:"read_timeout" yaml:"read_timeout"`
	// WriteTimeout: Durée maximale pour écrire la réponse.
	WriteTimeout time.Duration `json:"write_timeout" yaml:"write_timeout"`
	// IdleTimeout: Durée maximale d'attente pour la prochaine requête sur une connexion persistante.
	IdleTimeout time.Duration `json:"idle_timeout" yaml:"idle_timeout"`
	// DevMode: Active le mode développement (logs plus verbeux, pas de prefork, etc.).
	DevMode bool `json:"dev_mode" yaml:"dev_mode"`
	// Logger: L'instance du logger slog à utiliser par le serveur.
	Logger *slog.Logger `json:"-" yaml:"-"`
	// PublicDir: Chemin absolu du répertoire contenant les fichiers statiques publics servis par app.Static.
	PublicDir string `json:"public_dir" yaml:"public_dir"`
	// CacheDir: Chemin absolu du répertoire pour le cache L2 (BadgerDB). Si vide, L2 est désactivé.
	CacheDir string `json:"cache_dir" yaml:"cache_dir"`
	// SourcesDir: Chemin du répertoire contenant les sources CSS/JS à minifier.
	SourcesDir string `json:"sources_dir" yaml:"sources_dir"`
	// StaticsDir: Chemin du répertoire contenant les fichiers statiques à copier directement dans PublicDir.
	StaticsDir string `json:"statics_dir" yaml:"statics_dir"`
	// ErrorHandler: Fonction personnalisée pour gérer les erreurs Fiber. Si nil, utilise le gestionnaire par défaut.
	ErrorHandler func(c *fiber.Ctx, err error) error `json:"-" yaml:"-"`
	// NotFoundComponent: Composant Templ à afficher pour les erreurs 404 (non implémenté actuellement dans handleError).
	NotFoundComponent templ.Component `json:"-" yaml:"-"`
	// ErrorComponentGenerator: Fonction qui génère un composant Templ pour afficher une page d'erreur.
	ErrorComponentGenerator ErrorComponentGenerator `json:"-" yaml:"-"`
	// CacheL1DefaultTTL: Durée de vie par défaut pour les éléments dans le cache L1 (mémoire). `0` ou négatif signifie pas d'expiration automatique (utilisé avec `IsInfinite`).
	CacheL1DefaultTTL time.Duration `json:"cache_l1_default_ttl" yaml:"cache_l1_default_ttl"`
	// CacheL2DefaultTTL: Durée de vie par défaut pour les éléments dans le cache L2 (BadgerDB). `0` ou négatif signifie pas d'expiration automatique.
	CacheL2DefaultTTL time.Duration `json:"cache_l2_default_ttl" yaml:"cache_l2_default_ttl"`
	// BadgerGCInterval: Intervalle pour le déclenchement du Garbage Collector de BadgerDB. `0` ou négatif désactive le GC périodique.
	BadgerGCInterval time.Duration `json:"badger_gc_interval" yaml:"badger_gc_interval"`
	// BadgerGCDiscardRatio: Ratio utilisé par le GC de BadgerDB (généralement 0.5).
	BadgerGCDiscardRatio float64 `json:"badger_gc_discard_ratio" yaml:"badger_gc_discard_ratio"`
	// WarmupConcurrency: Nombre maximum de goroutines pour exécuter le préchauffage du cache en parallèle.
	WarmupConcurrency int `json:"warmup_concurrency" yaml:"warmup_concurrency"`
	// EnableCSRF: Active ou désactive la protection CSRF via middleware.
	EnableCSRF bool `json:"enable_csrf" yaml:"enable_csrf"`
	// CSRFKeyLookup: Source où chercher le jeton CSRF dans la requête (ex: "header:X-CSRF-Token"). Voir la documentation Fiber CSRF.
	CSRFKeyLookup string `json:"csrf_key_lookup" yaml:"csrf_key_lookup"`
	// CSRFCookieName: Nom du cookie utilisé pour stocker le secret CSRF.
	CSRFCookieName string `json:"csrf_cookie_name" yaml:"csrf_cookie_name"`
	// CSRFExpiration: Durée de validité du jeton CSRF.
	CSRFExpiration time.Duration `json:"csrf_expiration" yaml:"csrf_expiration"`
	// CSRFCookieSameSite: Politique SameSite pour le cookie CSRF ("Lax", "Strict", "None").
	CSRFCookieSameSite string `json:"csrf_cookie_same_site" yaml:"csrf_cookie_same_site"`
	// EnableRateLimiter: Active ou désactive le middleware de limitation de débit.
	EnableRateLimiter bool `json:"enable_rate_limiter" yaml:"enable_rate_limiter"`
	// RateLimiterMax: Nombre maximum de requêtes autorisées par fenêtre de temps.
	RateLimiterMax int `json:"rate_limiter_max" yaml:"rate_limiter_max"`
	// RateLimiterExpiration: Durée de la fenêtre de temps pour la limitation de débit.
	RateLimiterExpiration time.Duration `json:"rate_limiter_expiration" yaml:"rate_limiter_expiration"`
	// SecurityHeaders: Map des en-têtes HTTP de sécurité à ajouter à chaque réponse.
	SecurityHeaders map[string]string `json:"security_headers" yaml:"security_headers"`
	// EnableMetrics: Active ou désactive l'exposition des métriques Prometheus via /metrics.
	EnableMetrics bool `json:"enable_metrics" yaml:"enable_metrics"`
	// CustomMiddlewares: Slice de middlewares Fiber personnalisés à ajouter à la chaîne globale.
	CustomMiddlewares []fiber.Handler `json:"-" yaml:"-"`
}

// BytesGeneratorFunc définit la signature d'une fonction utilisée pour générer
// des données binaires (ex: sitemap XML) pour le cache.
// Doit retourner les données, un timestamp Unix de dernière modification, et une erreur éventuelle.
type BytesGeneratorFunc func() (data []byte, lastModified int64, err error)

// PageGeneratorFunc définit la signature d'une fonction utilisée pour générer
// une page HTML (via un composant Templ) pour le cache.
// Doit retourner le composant, un timestamp Unix de dernière modification, et une erreur éventuelle.
type PageGeneratorFunc func() (page templ.Component, lastModified int64, err error)

// CacheTTLInfo spécifie si une entrée de cache doit avoir une durée de vie infinie.
type CacheTTLInfo struct {
	IsInfinite bool
}

// WarmupRegistration contient les informations nécessaires pour enregistrer un élément
// pour le préchauffage du cache (clé, fonction de génération, type, TTL).
type WarmupRegistration struct {
	Key           string
	GeneratorFunc interface{} // Doit être casté en BytesGeneratorFunc ou PageGeneratorFunc
	IsBytes       bool
	TTLInfo       CacheTTLInfo
}

// ErrorComponentGenerator définit la signature d'une fonction qui génère un composant Templ
// pour afficher une page d'erreur basée sur l'erreur, le code HTTP et le mode de développement.
type ErrorComponentGenerator func(err error, code int, isDev bool) templ.Component

// CSRFContextKey est la clé utilisée pour stocker/récupérer le jeton CSRF dans les locaux du contexte Fiber.
const CSRFContextKey = "csrf"


# File: package:github.com/r-via/blitzkit/utils.go
# ------------------------------------------------------------
// File: utils.go
// Description: Fournit diverses fonctions utilitaires pour le package blitzkit,
//
//	telles que l'extraction d'IP client, la gestion des valeurs par défaut,
//	la vérification de répertoires, et la détection des requêtes JSON.
package blitzkit

import (
	"errors"
	"fmt"
	"log/slog"
	"os"
	"path/filepath"
	"strconv"
	"strings"
	"time"

	"github.com/gofiber/fiber/v2"
)

// GetClientIP extrait l'adresse IP du client à partir des en-têtes de la requête.
// Priorise l'en-tête `X-Forwarded-For` (en prenant la première IP de la liste si présente),
// puis utilise l'adresse distante (`RemoteAddr`) du contexte Fiber comme repli.
//
// Args:
//
//	xForwardedFor (string): La valeur de l'en-tête `X-Forwarded-For`.
//	remoteAddr (string): L'adresse distante provenant du contexte Fiber.
//
// Returns:
//
//	string: L'adresse IP extraite du client.
func GetClientIP(xForwardedFor, remoteAddr string) string {
	if xForwardedFor != "" {
		ips := strings.Split(xForwardedFor, ",")
		clientIP := strings.TrimSpace(ips[0])
		if clientIP != "" {
			return clientIP
		}
	}
	ipPort := strings.Split(remoteAddr, ":")
	if len(ipPort) > 0 && ipPort[0] != "" {
		return ipPort[0]
	}
	return remoteAddr
}

// defaultDuration retourne la `value` si elle est positive (> 0), sinon retourne `defaultValue`.
// Utile pour définir des timeouts ou intervalles avec des valeurs par défaut saines.
//
// Args:
//
//	value (time.Duration): La valeur de durée potentielle.
//	defaultValue (time.Duration): La valeur par défaut à utiliser si `value` n'est pas positive.
//
// Returns:
//
//	time.Duration: La durée effective.
func defaultDuration(value, defaultValue time.Duration) time.Duration {
	if value > 0 {
		return value
	}
	return defaultValue
}

// defaultInt retourne la `value` si elle est différente de zéro, sinon retourne `defaultValue`.
//
// Args:
//
//	value (int): La valeur entière potentielle.
//	defaultValue (int): La valeur par défaut à utiliser si `value` est zéro.
//
// Returns:
//
//	int: La valeur entière effective.
func defaultInt(value, defaultValue int) int {
	if value != 0 {
		return value
	}
	return defaultValue
}

// parseDurationEnv tente de parser une durée à partir d'une variable d'environnement.
// Si la variable d'environnement existe et est valide, sa valeur est utilisée.
// Sinon, si `configValue` est positive, elle est utilisée.
// Sinon, `defaultValue` est utilisée. Logue la source de la valeur utilisée.
//
// Args:
//
//	key (string): Le nom de la variable d'environnement.
//	configValue (time.Duration): La valeur provenant potentiellement d'une structure de configuration.
//	defaultValue (time.Duration): La valeur par défaut ultime.
//	logger (*slog.Logger): Le logger pour enregistrer la source de la valeur.
//
// Returns:
//
//	time.Duration: La durée effective déterminée.
func parseDurationEnv(key string, configValue time.Duration, defaultValue time.Duration, logger *slog.Logger) time.Duration {
	log := logger
	if log == nil {
		log = slog.Default()
	}

	envStr := os.Getenv(key)
	if envStr != "" {
		d, err := time.ParseDuration(envStr)
		if err == nil {
			log.Debug("Using duration from environment variable", "var", key, "value", d)
			return d
		}
		log.Warn("Invalid duration format in environment variable, falling back", "var", key, "value", envStr, "error", err)
	}
	if configValue > 0 {
		log.Debug("Using duration from configuration", "var", key, "value", configValue)
		return configValue
	}
	log.Debug("Using default duration", "var", key, "value", defaultValue)
	return defaultValue
}

// checkDirWritable vérifie si un répertoire donné existe et est accessible en écriture
// en tentant de créer puis supprimer un fichier temporaire à l'intérieur.
//
// Args:
//
//	dir (string): Le chemin du répertoire à vérifier.
//	logger (*slog.Logger): Le logger pour enregistrer les erreurs ou avertissements.
//
// Returns:
//
//	error: Une erreur si le chemin est invalide, n'est pas un répertoire,
//	       n'est pas accessible en écriture, ou si une erreur système survient. Nil si le répertoire est accessible en écriture.
func checkDirWritable(dir string, logger *slog.Logger) error {
	log := logger
	if log == nil {
		log = slog.Default()
	}

	if dir == "" {
		return errors.New("directory path cannot be empty for write check")
	}
	info, err := os.Stat(dir)
	if err != nil {
		log.Error("Cannot check writability, directory stat failed", "path", dir, "error", err)
		return fmt.Errorf("cannot check writability for %s: %w", dir, err)
	}
	if !info.IsDir() {
		log.Error("Cannot check writability, path is not a directory", "path", dir)
		return fmt.Errorf("cannot check writability, %s is not a directory", dir)
	}

	testFileName := ".write_test." + strconv.FormatInt(time.Now().UnixNano(), 10) + ".tmp"
	testFile := filepath.Join(dir, testFileName)

	f, err := os.Create(testFile)
	if err != nil {
		if errors.Is(err, os.ErrPermission) {
			log.Error("Permission denied: Cannot write in directory", "path", dir)
			return fmt.Errorf("permission denied writing to directory %s: %w", dir, err)
		}
		log.Error("Failed to create test file for write check", "path", testFile, "error", err)
		return fmt.Errorf("cannot create test file in %s: %w", dir, err)
	}

	closeErr := f.Close()
	removeErr := os.Remove(testFile)
	if closeErr != nil {
		log.Warn("Failed to close test file handle after write check", "path", testFile, "error", closeErr)
	}
	if removeErr != nil {
		log.Warn("Failed to remove write test file after creation", "path", testFile, "error", removeErr)
	}

	return nil
}

// ensureDirExists vérifie si un répertoire existe au chemin spécifié. S'il n'existe pas,
// il tente de le créer (ainsi que tous les répertoires parents nécessaires).
// Retourne une erreur si le chemin existe mais n'est pas un répertoire, ou si la création échoue.
//
// Args:
//
//	dir (string): Le chemin du répertoire à vérifier/créer.
//	logger (*slog.Logger): Le logger pour enregistrer les actions ou erreurs.
//
// Returns:
//
//	error: Une erreur si le chemin est invalide, si ce n'est pas un répertoire, ou si la création échoue. Nil sinon.
func ensureDirExists(dir string, logger *slog.Logger) error {
	log := logger
	if log == nil {
		log = slog.Default()
	}
	if dir == "" {
		return errors.New("directory path cannot be empty for ensureDirExists")
	}

	info, err := os.Stat(dir)
	if err == nil {
		if info.IsDir() {
			return nil
		}
		return fmt.Errorf("path %s exists but is not a directory", dir)
	}

	if errors.Is(err, os.ErrNotExist) {
		if errMkdir := os.MkdirAll(dir, 0755); errMkdir != nil {
			log.Error("Failed to create directory path", "path", dir, "error", errMkdir)
			return fmt.Errorf("failed to create directory %s: %w", dir, errMkdir)
		}
		log.Debug("Created directory", "path", dir)
		return nil
	}

	log.Error("Failed to stat directory for ensureDirExists check", "path", dir, "error", err)
	return fmt.Errorf("failed to check directory %s: %w", dir, err)
}

// WantsJSON vérifie si l'en-tête `Accept` de la requête indique une préférence pour le format JSON.
//
// Args:
//
//	c (*fiber.Ctx): Le contexte Fiber de la requête.
//
// Returns:
//
//	bool: true si l'en-tête `Accept` contient "application/json", sinon false.
func WantsJSON(c *fiber.Ctx) bool {
	if c == nil {
		slog.Default().Warn("WantsJSON called with nil context")
		return false
	}
	return strings.Contains(strings.ToLower(c.Get(fiber.HeaderAccept)), fiber.MIMEApplicationJSON)
}

// getEnvOrDefault récupère une variable d'environnement, en utilisant une valeur de configuration
// ou une valeur par défaut comme repli. Logue la source de la valeur utilisée.
//
// Args:
//
//	logger (*slog.Logger): Le logger pour enregistrer la source.
//	key (string): Le nom de la variable d'environnement.
//	configValue (string): La valeur provenant potentiellement d'une configuration.
//	defaultValue (string): La valeur par défaut ultime.
//
// Returns:
//
//	string: La valeur effective déterminée.
func getEnvOrDefault(logger *slog.Logger, key, configValue, defaultValue string) string {
	log := logger
	if log == nil {
		log = slog.Default()
	}

	if envVal := os.Getenv(key); envVal != "" {
		log.Debug("Using value from environment variable", "var", key)
		return envVal
	}
	if configValue != "" {
		log.Debug("Using value from configuration", "var", key)
		return configValue
	}
	log.Debug("Using default value", "var", key, "value", defaultValue)
	return defaultValue
}


